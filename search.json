[{"path":"https://p-wegmueller.github.io/reviser/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 reviser authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/efficient-release.html","id":"optimal-properties-of-revisions","dir":"Articles","previous_headings":"","what":"Optimal Properties of Revisions","title":"Identifying an Efficient Release in Data Subject to Revisions","text":"Data revisions can classified two main types: ongoing revisions, incorporate new information becomes available, benchmark revisions, reflect changes definitions, classifications, methodologies. Optimally, revisions satisfy following properties (Aruoba 2008): Unbiasedness: Revisions systematically push estimates one direction. Mathematically, revision series rtf=ytf−ythr_t^f = y_t^f - y_t^h hh denotes release number ytfy_t^f represents final release ythy_t^h represents series released time hh (h=0h=0 initial release), unbiasedness requires: E[rtf]=0 E[r_t^f] = 0 Efficiency: efficient release incorporates available information optimally, ensuring subsequent revisions unpredictable. can tested using Mincer-Zarnowitz regression: ytf=α+βyth+εt, y_t^f = \\alpha + \\beta y_t^h + \\varepsilon_t,  efficient release satisfies α=0\\alpha = 0 β=1\\beta = 1. Minimal Variance: Revisions small possible still improving accuracy. variance revisions, defined Var(rtf)\\text{Var}(r_t^f), decrease successive releases.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/efficient-release.html","id":"initial-estimates-as-truth-measured-with-noise","dir":"Articles","previous_headings":"","what":"Initial Estimates as Truth Measured with Noise","title":"Identifying an Efficient Release in Data Subject to Revisions","text":"fundamental assumption many revision models first release data point imperfect measure true value due measurement errors. can expressed : yth=yt*+εth, y_t^h = y_t^* + \\varepsilon_t^h,  yt*y_t^* true value εth\\varepsilon_t^h error term diminishes hh increases. properties rthr_t^h determine whether preliminary release hh efficient estimator yt*y_t^*. rthr_t^h predictable, revision process inefficient, indicating room improvement initial estimates. Vice-versa rthr_t^h unpredictable, preliminary release efficient (.e yth=ytey_t^h = y_t^e).","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/efficient-release.html","id":"the-challenge-of-defining-a-final-release","dir":"Articles","previous_headings":"","what":"The Challenge of Defining a Final Release","title":"Identifying an Efficient Release in Data Subject to Revisions","text":"One major challenge identifying efficient release using Mincer-Zarnowitz regressions often unclear data release considered final. revisions occur due incorporation new information, others result methodological changes redefine past values. Consequently, statistical agencies may continue revising data years, making difficult pinpoint definitive final release. instance Germany final release national accounts data typically published four years initial release. Switzerland, GDP figures never finalized. , defining final release non-trivial task requires knowledge revision process.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/efficient-release.html","id":"iterative-approach-for-identifying-e","dir":"Articles","previous_headings":"","what":"Iterative Approach for Identifying ee","title":"Identifying an Efficient Release in Data Subject to Revisions","text":"iterative approach proposed determine optimal number revisions, ee, beyond revisions negligible. approach based running Mincer-Zarnowitz-style regressions assess release provides optimal estimate final value. procedure follows steps (Kishor Koenig 2012; Strohsal Wolf 2020): Regression Analysis: Regress final release ytfy_t^f initial releases ythy_t^h h=1,2,…,eh = 1,2,\\dots,e: ytf=α+βyth+εt y_t^f = \\alpha + \\beta y_t^h + \\varepsilon_t  null hypothesis α=0\\alpha = 0 β=1\\beta = 1, indicating ythy_t^h efficient estimate ytfy_t^f. Determine Optimal ee: Increase hh iteratively test whether efficiency conditions hold. smallest ee hypothesis rejected considered final efficient release.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/efficient-release.html","id":"importance-of-an-efficient-release","dir":"Articles","previous_headings":"","what":"Importance of an Efficient Release","title":"Identifying an Efficient Release in Data Subject to Revisions","text":"efficient release essential various economic applications: Macroeconomic Policy Decisions: Monetary fiscal policies depend timely reliable data. initial releases biased predictable, policymakers may react inappropriately, leading suboptimal policy outcomes. Nowcasting Forecasting: Reliable early estimates improve accuracy nowcasting models, used real-time assessment economic conditions. Financial Market Stability: Investors base decisions official economic data. initial releases misleading, market volatility may increase due unexpected revisions. International Comparisons: Cross-country analyses require consistent data. national statistical agencies release inefficient estimates, international comparisons become distorted. optimal revision process one leads unbiased, efficient, minimally variant data revisions. Initial estimates represent truth measured noise, identifying efficient release allows analysts determine earliest point data can used reliably without concern systematic revisions. iterative approach based Mincer-Zarnowitz regressions provides robust framework achieving goal, improving reliability macroeconomic data forecasting policy analysis.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/efficient-release.html","id":"example-identifying-an-efficient-release-in-gdp-data-with-reviser","dir":"Articles","previous_headings":"","what":"Example: Identifying an Efficient Release in GDP Data with reviser","title":"Identifying an Efficient Release in Data Subject to Revisions","text":"following example, use reviser package identify efficient release quarterly GDP data Switzerland, Euro Area, Japan, United States. test first 20 data releases, aim determine point revisions become negligible. final release, use release countries, namely data released 5 years first release. tests shows first efficient release occurs different points country, ranging 1st (Japan, US) 13th (Switzerland) release. Note: identification first efficient release related news hypothesis testing. Hence, conclusion reached using function get_revision_analysis() (setting degree=3, providing results news noise tests) shown . advantage using get_first_efficient_release() function organizes data subsequently used kk_nowcast() improve nowcasts preliminary releases (See vignette Nowcasting Revisions details).","code":"library(reviser) library(dplyr)  gdp <- reviser::gdp %>%   tsbox::ts_pc()   df <- get_nth_release(gdp, n = 0:19)  final_release <- get_nth_release(gdp, n = 20)  efficient <- get_first_efficient_release(   df,   final_release )  res <- summary(efficient) #> id:  CHE  #> Efficient release:  13  #>  #> Model summary:  #>  #> Call: #> stats::lm(formula = formula, data = df_wide) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -0.83040 -0.13561 -0.00657  0.15531  0.76670  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  0.05979    0.02526   2.367   0.0192 *   #> release_13   0.87766    0.03326  26.384   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.2631 on 155 degrees of freedom #>   (21 observations deleted due to missingness) #> Multiple R-squared:  0.8179, Adjusted R-squared:  0.8167  #> F-statistic: 696.1 on 1 and 155 DF,  p-value: < 2.2e-16 #>  #>  #> Test summary:  #>  #> Linear hypothesis test: #> (Intercept) = 0 #> release_13 = 1 #>  #> Model 1: restricted model #> Model 2: final ~ release_13 #>  #> Note: Coefficient covariance matrix supplied. #>  #>   Res.Df Df      F  Pr(>F)   #> 1    157                     #> 2    155  2 2.9999 0.05269 . #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #>  #> id:  EA  #> Efficient release:  7  #>  #> Model summary:  #>  #> Call: #> stats::lm(formula = formula, data = df_wide) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -0.39144 -0.06507  0.00536  0.07090  0.25743  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  0.01982    0.01113   1.781   0.0768 .   #> release_7    1.00311    0.01646  60.934   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.1111 on 156 degrees of freedom #>   (20 observations deleted due to missingness) #> Multiple R-squared:  0.9597, Adjusted R-squared:  0.9594  #> F-statistic:  3713 on 1 and 156 DF,  p-value: < 2.2e-16 #>  #>  #> Test summary:  #>  #> Linear hypothesis test: #> (Intercept) = 0 #> release_7 = 1 #>  #> Model 1: restricted model #> Model 2: final ~ release_7 #>  #> Note: Coefficient covariance matrix supplied. #>  #>   Res.Df Df      F  Pr(>F)   #> 1    158                     #> 2    156  2 3.0071 0.05231 . #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #>  #> id:  JP  #> Efficient release:  0  #>  #> Model summary:  #>  #> Call: #> stats::lm(formula = formula, data = df_wide) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.76370 -0.36739 -0.01023  0.38499  1.72906  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  0.05437    0.05116   1.063     0.29     #> release_0    0.83179    0.04878  17.051   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.5765 on 156 degrees of freedom #>   (20 observations deleted due to missingness) #> Multiple R-squared:  0.6508, Adjusted R-squared:  0.6486  #> F-statistic: 290.7 on 1 and 156 DF,  p-value: < 2.2e-16 #>  #>  #> Test summary:  #>  #> Linear hypothesis test: #> (Intercept) = 0 #> release_0 = 1 #>  #> Model 1: restricted model #> Model 2: final ~ release_0 #>  #> Note: Coefficient covariance matrix supplied. #>  #>   Res.Df Df      F Pr(>F) #> 1    158                  #> 2    156  2 1.8585 0.1593 #>  #>  #> id:  US  #> Efficient release:  0  #>  #> Model summary:  #>  #> Call: #> stats::lm(formula = formula, data = df_wide) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -0.82880 -0.13760  0.03239  0.12910  0.95887  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 0.005432   0.028360   0.192    0.848     #> release_0   0.955730   0.029993  31.865   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.2564 on 156 degrees of freedom #>   (20 observations deleted due to missingness) #> Multiple R-squared:  0.8668, Adjusted R-squared:  0.866  #> F-statistic:  1015 on 1 and 156 DF,  p-value: < 2.2e-16 #>  #>  #> Test summary:  #>  #> Linear hypothesis test: #> (Intercept) = 0 #> release_0 = 1 #>  #> Model 1: restricted model #> Model 2: final ~ release_0 #>  #> Note: Coefficient covariance matrix supplied. #>  #>   Res.Df Df      F Pr(>F) #> 1    158                  #> 2    156  2 2.2919 0.1045  head(res) #> # A tibble: 4 × 6 #>   id        e   alpha  beta p_value n_tested #>   <chr> <dbl>   <dbl> <dbl>   <dbl>    <int> #> 1 CHE      13 0.0598  0.878  0.0527       14 #> 2 EA        7 0.0198  1.00   0.0523        8 #> 3 JP        0 0.0544  0.832  0.159         1 #> 4 US        0 0.00543 0.956  0.104         1 analysis <- get_revision_analysis(   df,    final_release,   degree=3   ) head(analysis) #> # A tibble: 6 × 17 #>   id    release        N `News test Intercept` `News test Intercept (std.err)` #>   <chr> <chr>      <dbl>                 <dbl>                           <dbl> #> 1 CHE   release_0    158                0.180                           0.0540 #> 2 CHE   release_1    158                0.163                           0.0544 #> 3 CHE   release_10   157                0.128                           0.0475 #> 4 CHE   release_11   158                0.126                           0.0469 #> 5 CHE   release_12   157                0.0920                          0.0406 #> 6 CHE   release_13   157                0.0598                          0.0292 #> # ℹ 12 more variables: `News test Intercept (p-value)` <dbl>, #> #   `News test Coefficient` <dbl>, `News test Coefficient (std.err)` <dbl>, #> #   `News test Coefficient (p-value)` <dbl>, `News joint test (p-value)` <dbl>, #> #   `Noise test Intercept` <dbl>, `Noise test Intercept (std.err)` <dbl>, #> #   `Noise test Intercept (p-value)` <dbl>, `Noise test Coefficient` <dbl>, #> #   `Noise test Coefficient (std.err)` <dbl>, #> #   `Noise test Coefficient (p-value)` <dbl>, …"},{"path":[]},{"path":"https://p-wegmueller.github.io/reviser/articles/literature-review.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"The Role and Importance of Revisions in Time Series Data","text":"Revisions time series data, particularly official statistics, serve integral component statistical quality management. preliminary estimates provide timely information, subsequent revisions refine figures, ensuring accuracy alignment reality. study revisions long area interest statistical economic literature, researchers statistical agencies recognizing significance evaluating data reliability, improving forecasting models, enhancing policymaking (Eurostat 2023; National Statistics 2024).","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/literature-review.html","id":"understanding-the-magnitude-of-revisions","dir":"Articles","previous_headings":"","what":"Understanding the Magnitude of Revisions","title":"The Role and Importance of Revisions in Time Series Data","text":"fundamental aspect revision studies involves measuring magnitude changes initial estimates final values. Large revisions can indicate deficiencies early estimation methods, minimal revisions suggest preliminary figures already close true values. Statistical agencies U.S. Bureau Economic Analysis (BEA), Eurostat, Office National Statistics (ONS) monitor revision magnitudes assess data quality methodological consistency (Eurostat 2023; Bureau Economic Analysis 2024). One key reason analyzing revision magnitude detect systematic biases. revisions consistently move one direction—upward downward—suggests systematic underestimation overestimation initial estimates (J. Faust Wright 2005). example, GDP estimates many countries tend revised upward comprehensive tax business data become available, revealing early estimates often underestimate economic activity (Aruoba 2008). Beyond identifying biases, revision magnitude crucial policymakers financial markets. Large revisions imply initial data releases may reliable real-time decision-making. Central banks, example, base monetary policy decisions indicators inflation, GDP growth, unemployment. figures later subject substantial revisions, policy measures may misaligned actual state economy (Croushore Stark 2003).","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/literature-review.html","id":"the-dynamics-of-revisions-and-what-they-reveal","dir":"Articles","previous_headings":"","what":"The Dynamics of Revisions and What They Reveal","title":"The Role and Importance of Revisions in Time Series Data","text":"Beyond magnitude, study revision patterns time reveals important insights data reliability, economic fluctuations, statistical methodologies. persistence revisions—whether initial errors short-lived remain consistent multiple revisions—indicates whether early estimates contain useful signals merely statistical noise (Mankiw Shapiro 1986). Revisions also tend vary across different phases economic cycle. Research shown economic downturns, GDP employment figures often undergo larger downward revisions periods economic stability (Sinclair Stekler 2013). partly downturns involve sudden shifts business conditions fully captured early estimates, requiring later revisions data become available.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/literature-review.html","id":"the-uses-of-studying-revisions-in-time-series-data","dir":"Articles","previous_headings":"","what":"The Uses of Studying Revisions in Time Series Data","title":"The Role and Importance of Revisions in Time Series Data","text":"analysis revisions several practical applications statistics, economics, policy. First, enhances forecasting accuracy. Economic models rely historical data, understanding revision patterns helps forecasters adjust models anticipate changes early estimates (Croushore 2011). Revisions also provide insights statistical methodology data collection processes. examining variables tend heavily revised, statistical agencies can refine estimation techniques improve early releases (Eurostat 2023). ONS (National Statistics 2024) similarly notes rebasing statistical indices integrating new data sources can improve stability revisions time. Another critical use revision studies policymaking. Governments central banks need reliable data make informed decisions, awareness revision trends allows interpret initial estimates appropriate level caution. policymakers advocate publication confidence intervals around preliminary estimates convey uncertainty associated early releases (Manski 2014). Transparency revision processes essential maintaining credibility. Statistical agencies increasingly publish detailed revision histories, allowing users track changes time. BEA, example, provides documentation GDP estimates evolve preliminary final releases, helping economists understand sources scale revisions (Bureau Economic Analysis 2024).","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/literature-review.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"The Role and Importance of Revisions in Time Series Data","text":"Studying revisions time series data fundamental ensuring accuracy, reliability, transparency official statistics. Measuring magnitude revisions allows researchers policymakers assess credibility initial estimates, detect systematic biases, refine statistical methodologies. Analyzing dynamics revisions sheds light data reliability, economic cycle effects, forecasting challenges. Furthermore, revision studies play critical role improving statistical methods, informing policymaking, enhancing public confidence official statistics.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/nowcasting-revisions.html","id":"the-generalized-kishor-koenig-model","dir":"Articles","previous_headings":"","what":"The Generalized Kishor-Koenig Model","title":"Nowcasting Revisions","text":"KK model extends traditional Vector Autoregression (VAR) framework account data revisions explicitly. Unlike conventional models treat data final accurate, KK model recognizes initial releases subject revisions, leading biased inefficient forecasts. incorporating revision process state-space framework, KK model provides reliable approach nowcasting economic variables. Moreover, nests several nowcasting models, classical textbook measurement error model Howrey (1978) model. procedure based assumption exists efficient estimate ytey_t^e final release becomes available ee periods initial release yt0y_t^0. follow Strohsal Wolf (2020) assume eeth revision data follows autoregressive model order one (AR(1)). state-space representation KK model given : 1. State Equation zt=Fzt−1+νt z_t = F z_{t-1} + \\nu_t 2. Observation Equation yt=(−G)Fyt−1+Gzt+ϵt,y_t = (- G) F y_{t-1} + G z_t + \\epsilon_t, z′t=[yt−ee,yt−e+1e,...,yte]′ z'_t = \\begin{bmatrix} y_{t-e}^e, y_{t-e +1}^e, ...,  y_t^e \\end{bmatrix}' y′t=[yt−ee,yt−e+1e−1,...,yt0]′ y'_t = \\begin{bmatrix} y_{t-e}^e, y_{t-e +1}^{e-1}, ...,  y_t^0 \\end{bmatrix}' ν′t=[0,0,...,ν0,t]′ \\nu'_t = \\begin{bmatrix} 0, 0, ...,  \\nu_{0,t} \\end{bmatrix}' ϵ′t=[0,ϵe−1,t,...,ϵ1,t,ϵ0,t]′ \\epsilon'_t = \\begin{bmatrix} 0, \\epsilon_{e-1,t}, ...,  \\epsilon_{1,t}, \\epsilon_{0,t} \\end{bmatrix}' F=[010…0001…0⋮⋮⋮⋱⋮000…1000…F0] F = \\begin{bmatrix} 0 & 1 & 0 & \\dots & 0 \\\\                       0 & 0 & 1 & \\dots & 0 \\\\                       \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\                       0 & 0 & 0 & \\dots & 1 \\\\                       0 & 0 & 0 & \\dots & F_0 \\end{bmatrix} G=[10…0Ge−1,eGe−1,e−1…Ge−1,0Ge−2,eGe−2,e−1…Ge−2,0⋮⋮⋱⋮G0,eG0,e−1…G0,0] G = \\begin{bmatrix} 1 & 0 & \\dots & 0 \\\\                       G_{e-1,e} & G_{e-1,e-1} & \\dots & G_{e-1,0} \\\\                       G_{e-2,e} & G_{e-2,e-1} & \\dots & G_{e-2,0} \\\\                       \\vdots & \\vdots & \\ddots & \\vdots \\\\                       G_{0,e} & G_{0,e-1} & \\dots & G_{0,0} \\end{bmatrix} GG gain matrix capturing weight placed new information, FF determines AR coefficient, νt\\nu_t ϵt\\epsilon_t error vectors. state-equation observation-equation error vectors assumed uncorrelated one another leads lags, serially uncorrelated. recommended estimate system using seemingly unrelated regression (SUR) account correlation error terms state observation equations. SUR estimation implemented seem package, provides convenient interface estimate state-space models R.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/nowcasting-revisions.html","id":"state-space-representation","dir":"Articles","previous_headings":"The Generalized Kishor-Koenig Model","what":"2.2 State-Space Representation","title":"Nowcasting Revisions","text":"KK model formulated state-space system, consisting state equation describing evolution true economic variable observation equation relating observed releases true value.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/nowcasting-revisions.html","id":"state-equation","dir":"Articles","previous_headings":"The Generalized Kishor-Koenig Model > 2.2 State-Space Representation","what":"State Equation","title":"Nowcasting Revisions","text":"true value follows autoregressive process: xt=Fxt−1+νt, x_t = F x_{t-1} + \\nu_t,  FF coefficient matrix νt\\nu_t white noise error term.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/nowcasting-revisions.html","id":"observation-equation","dir":"Articles","previous_headings":"The Generalized Kishor-Koenig Model > 2.2 State-Space Representation","what":"Observation Equation","title":"Nowcasting Revisions","text":"Observed releases linked true value : yti=(−G)Fyt−1i+Gxt+ϵti, y_t^= (- G) F y_{t-1}^+ G x_t + \\epsilon_t^,  GG gain matrix capturing weight placed new information, ϵti\\epsilon_t^measurement error. matrices governing revision process, FF GG, structured : F=[010…0001…0⋮⋮⋮⋱⋮000…1000…F0], F = \\begin{bmatrix} 0 & 1 & 0 & \\dots & 0 \\\\                       0 & 0 & 1 & \\dots & 0 \\\\                       \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\                       0 & 0 & 0 & \\dots & 1 \\\\                       0 & 0 & 0 & \\dots & F_0 \\end{bmatrix}, G=[10…0Ge−1,eGe−1,e−1…Ge−1,0Ge−2,eGe−2,e−1…Ge−2,0⋮⋮⋱⋮G0,eG0,e−1…G0,0]. G = \\begin{bmatrix} 1 & 0 & \\dots & 0 \\\\                       G_{e-1,e} & G_{e-1,e-1} & \\dots & G_{e-1,0} \\\\                       G_{e-2,e} & G_{e-2,e-1} & \\dots & G_{e-2,0} \\\\                       \\vdots & \\vdots & \\ddots & \\vdots \\\\                       G_{0,e} & G_{0,e-1} & \\dots & G_{0,0} \\end{bmatrix}. matrices determine revisions evolve time efficiently new information incorporated data releases.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/nowcasting-revisions.html","id":"model-estimation","dir":"Articles","previous_headings":"The Generalized Kishor-Koenig Model","what":"2.3 Model Estimation","title":"Nowcasting Revisions","text":"KK model estimated using Seemingly Unrelated Regression (SUR) method, allowing correlations measurement errors underlying economic variable. Kalman filter applied extract best estimate xtx_t observed data series ytiy_t^. Kalman update step given : x̂t=F̂x̂t−1+K(yt−Hx̂t), \\hat{x}_t = \\hat{F} \\hat{x}_{t-1} + K (y_t - H \\hat{x}_t),  KK Kalman gain matrix, HH observation mapping matrix. 3. Conclusion Kishor-Koenig model provides robust framework handling data revisions macroeconomic forecasting. autoregressive term revision process plays crucial role capturing persistence revisions, helps refine early estimates incorporating information past revisions. revisions predictable, accounted real-time estimates enhance forecast accuracy. explicitly modeling revision process, KK model offers significant improvement traditional VAR models, making valuable tool policymakers economists seeking generate accurate real-time estimates. use state-space approach, combined Kalman filtering, ensures forecasts dynamically updated new information becomes available.","code":"library(reviser) library(dplyr) library(lubridate)  gdp <- reviser::gdp %>%   tsbox::ts_pc() %>%   filter(id == \"US\",          time > min(pub_date),          time <= as.Date(\"2020-01-01\")          ) %>%   na.omit()  xx<-df %>% group_by(pub_date, release) %>%   mutate(n=n())  df <- gdp min_pub_date <- min(df$pub_date)       max_time <- max(df$time[df$pub_date == min_pub_date])       df <- df %>%         dplyr::filter(           time >= max_time         )        xx<-vintages_wide(df)$CHE  df <- get_nth_release(gdp, n = 0:14, diagonal = F)  final_release <- get_nth_release(gdp, n = 15) final_release <- get_nth_release(gdp, n = \"latest\")  efficient_release <- get_first_efficient_release(     df,     final_release   )  summary(efficient_release)   nowcast <- kk_nowcast(     efficient_release$data,      e = efficient_release$e,     model = \"KK\",     method = \"SUR\"#,     #solver_options = list(startvals = kk_nowcast(efficient_release$data, e = efficient_release$e, model = \"KK\", method = \"OLS\")$params)   )   nowcast$params summary(nowcast$fit[[1]]) xxx<-nowcast$filtered_z  eff_rel_pred_full <- (nowcast$filtered_states[,c(1,2+nowcast$e)])  final_vals <- vintages_wide(efficient_release$data, names_from = \"release\")[,c(\"time\", \"final\")]  first_vals <- vintages_wide(efficient_release$data, names_from = \"release\")[,c(1,2)]   data <- full_join(   first_vals,   eff_rel_pred_full,   by = \"time\" ) %>% full_join(   final_vals,   by = \"time\" ) %>% rename(   \"nowcast_full\" = 3,   \"final\" = 4,   \"first\" = 2 ) %>% arrange(time)  data1 <- na.omit(data) %>%   filter(!year(time) %in% c(2020, 2021)) %>%   mutate(     mse_full = mean((nowcast_full - final)^2),     mse_first = mean((first - final)^2)   )"},{"path":"https://p-wegmueller.github.io/reviser/articles/reviser.html","id":"package-conventions","dir":"Articles","previous_headings":"","what":"Package conventions","title":"Introduction to reviser","text":"conventional way represent vintage data real-time data matrix, row represents time period column represents successive releases data. known wide format. package supports data wide format. assumes data organized following columns: time, time period Publication dates 'yyyy-mm-dd' format release numbers release_# wide format practical inspection, data manipulation often easier long (tdy) format, consists : time, time period pub_date /release, publication date release number value, reported value. id, optional column distinguish different series illustration, package provides dataset long format, gdp. , examine GDP growth rates US Euro Area 2007–2009 financial crisis.","code":"# Example long-format US GDP data data(\"gdp\") gdp_us_short <- gdp %>%    dplyr::filter(id == \"US\") %>%   ts_pc() %>%   filter(     pub_date >= as.Date(\"2007-01-01\"),     pub_date < as.Date(\"2009-01-01\"),     time  >= as.Date(\"2007-01-01\"),     time < as.Date(\"2009-01-01\")   )  # Example long-format EA GDP data gdp_ea_short <- gdp %>%   dplyr::filter(id == \"EA\") %>%   ts_pc() %>%   filter(     pub_date >= as.Date(\"2007-01-01\"),     pub_date < as.Date(\"2009-01-01\"),     time  >= as.Date(\"2007-01-01\"),     time < as.Date(\"2009-01-01\")   )  head(gdp_ea_short) #> # A tibble: 6 × 4 #>   time       pub_date   value id    #>   <date>     <date>     <dbl> <chr> #> 1 2007-01-01 2007-04-01 0.603 EA    #> 2 2007-01-01 2007-07-01 0.707 EA    #> 3 2007-04-01 2007-07-01 0.349 EA    #> 4 2007-01-01 2007-10-01 0.780 EA    #> 5 2007-04-01 2007-10-01 0.310 EA    #> 6 2007-07-01 2007-10-01 0.714 EA"},{"path":"https://p-wegmueller.github.io/reviser/articles/reviser.html","id":"convert-long-to-wide-format","dir":"Articles","previous_headings":"","what":"Convert Long to Wide Format","title":"Introduction to reviser","text":"transform dataset long format wide format, use vintages_wide(). function requires columns time value, along either pub_date release. optional id column can used distinguish multiple series.","code":"# Convert wide-format data to long format wide_ea_short <- vintages_wide(gdp_ea_short) head(wide_ea_short) #> $EA #> # A tibble: 7 × 8 #>   time       `2007-04-01` `2007-07-01` `2007-10-01` `2008-01-01` `2008-04-01` #>   <date>            <dbl>        <dbl>        <dbl>        <dbl>        <dbl> #> 1 2007-01-01        0.603        0.707        0.780        0.789        0.745 #> 2 2007-04-01       NA            0.349        0.310        0.274        0.334 #> 3 2007-07-01       NA           NA            0.714        0.750        0.721 #> 4 2007-10-01       NA           NA           NA            0.382        0.352 #> 5 2008-01-01       NA           NA           NA           NA            0.800 #> 6 2008-04-01       NA           NA           NA           NA           NA     #> 7 2008-07-01       NA           NA           NA           NA           NA     #> # ℹ 2 more variables: `2008-07-01` <dbl>, `2008-10-01` <dbl>"},{"path":"https://p-wegmueller.github.io/reviser/articles/reviser.html","id":"convert-wide-to-long-format","dir":"Articles","previous_headings":"","what":"Convert Wide to Long Format","title":"Introduction to reviser","text":"revert long format, use vintages_long(). function expects column names wide format valid dates contain string \"release\".","code":"# Convert back to long format long_ea_short <- vintages_long(wide_ea_short) head(long_ea_short) #> # A tibble: 6 × 4 #>   time       pub_date   value id    #>   <date>     <chr>      <dbl> <chr> #> 1 2007-01-01 2007-04-01 0.603 EA    #> 2 2007-01-01 2007-07-01 0.707 EA    #> 3 2007-01-01 2007-10-01 0.780 EA    #> 4 2007-01-01 2008-01-01 0.789 EA    #> 5 2007-01-01 2008-04-01 0.745 EA    #> 6 2007-01-01 2008-07-01 0.745 EA"},{"path":"https://p-wegmueller.github.io/reviser/articles/reviser.html","id":"handling-multiple-series-with-id","dir":"Articles","previous_headings":"","what":"Handling Multiple Series with id","title":"Introduction to reviser","text":"id column present, vintages_wide() returns list one dataset per unique id. Conversely, vintages_long() maintains id column distinguish series.","code":"gdp_short <- bind_rows(   gdp_ea_short %>% mutate(id = \"EA\"),   gdp_us_short %>% mutate(id = \"US\") ) gdp_wide_short <- vintages_wide(gdp_short) head(gdp_wide_short) #> $EA #> # A tibble: 7 × 8 #>   time       `2007-04-01` `2007-07-01` `2007-10-01` `2008-01-01` `2008-04-01` #>   <date>            <dbl>        <dbl>        <dbl>        <dbl>        <dbl> #> 1 2007-01-01        0.603        0.707        0.780        0.789        0.745 #> 2 2007-04-01       NA            0.349        0.310        0.274        0.334 #> 3 2007-07-01       NA           NA            0.714        0.750        0.721 #> 4 2007-10-01       NA           NA           NA            0.382        0.352 #> 5 2008-01-01       NA           NA           NA           NA            0.800 #> 6 2008-04-01       NA           NA           NA           NA           NA     #> 7 2008-07-01       NA           NA           NA           NA           NA     #> # ℹ 2 more variables: `2008-07-01` <dbl>, `2008-10-01` <dbl> #>  #> $US #> # A tibble: 7 × 8 #>   time       `2007-04-01` `2007-07-01` `2007-10-01` `2008-01-01` `2008-04-01` #>   <date>            <dbl>        <dbl>        <dbl>        <dbl>        <dbl> #> 1 2007-01-01        0.162        0.150        0.150        0.150        0.150 #> 2 2007-04-01       NA            0.974        0.942        0.942        0.942 #> 3 2007-07-01       NA           NA            1.21         1.20         1.20  #> 4 2007-10-01       NA           NA           NA            0.156        0.144 #> 5 2008-01-01       NA           NA           NA           NA            0.224 #> 6 2008-04-01       NA           NA           NA           NA           NA     #> 7 2008-07-01       NA           NA           NA           NA           NA     #> # ℹ 2 more variables: `2008-07-01` <dbl>, `2008-10-01` <dbl>"},{"path":"https://p-wegmueller.github.io/reviser/articles/reviser.html","id":"extracting-releases","dir":"Articles","previous_headings":"","what":"Extracting Releases","title":"Introduction to reviser","text":"data follows package conventions, can analyzed . common task assessing first release data, corresponds diagonal real-time data matrix. Use get_nth_release() extract nth release. function 0-indexed, first release corresponds n = 0. assess data accuracy, need define final release. Since many statistical agencies continue revising data indefinitely, latest release often used benchmark. Use get_nth_release(n = \"latest\") extract recent vintage. agencies fix data certain period (e.g., Germany finalizes GDP data August four years initial release). function get_fixed_release() extracts fixed releases.","code":"# Get the first release and check in wide format gdp_releases <- get_nth_release(gdp_short, n = 0) vintages_wide(gdp_releases) #> Warning: Ignoring columns: release #> $EA #> # A tibble: 7 × 8 #>   time       `2007-04-01` `2007-07-01` `2007-10-01` `2008-01-01` `2008-04-01` #>   <date>            <dbl>        <dbl>        <dbl>        <dbl>        <dbl> #> 1 2007-01-01        0.603       NA           NA           NA           NA     #> 2 2007-04-01       NA            0.349       NA           NA           NA     #> 3 2007-07-01       NA           NA            0.714       NA           NA     #> 4 2007-10-01       NA           NA           NA            0.382       NA     #> 5 2008-01-01       NA           NA           NA           NA            0.800 #> 6 2008-04-01       NA           NA           NA           NA           NA     #> 7 2008-07-01       NA           NA           NA           NA           NA     #> # ℹ 2 more variables: `2008-07-01` <dbl>, `2008-10-01` <dbl> #>  #> $US #> # A tibble: 7 × 8 #>   time       `2007-04-01` `2007-07-01` `2007-10-01` `2008-01-01` `2008-04-01` #>   <date>            <dbl>        <dbl>        <dbl>        <dbl>        <dbl> #> 1 2007-01-01        0.162       NA            NA          NA           NA     #> 2 2007-04-01       NA            0.974        NA          NA           NA     #> 3 2007-07-01       NA           NA             1.21       NA           NA     #> 4 2007-10-01       NA           NA            NA           0.156       NA     #> 5 2008-01-01       NA           NA            NA          NA            0.224 #> 6 2008-04-01       NA           NA            NA          NA           NA     #> 7 2008-07-01       NA           NA            NA          NA           NA     #> # ℹ 2 more variables: `2008-07-01` <dbl>, `2008-10-01` <dbl>  # The function uses the pub_date column by default to define columns in wide  # format. Specifying the `names_from` argument allows to use the release column. gdp_releases <- get_nth_release(gdp_short, n = 0:1) vintages_wide(gdp_releases, names_from = \"release\") #> Warning: Ignoring columns: pub_date #> $EA #> # A tibble: 7 × 3 #>   time       release_0 release_1 #>   <date>         <dbl>     <dbl> #> 1 2007-01-01     0.603     0.707 #> 2 2007-04-01     0.349     0.310 #> 3 2007-07-01     0.714     0.750 #> 4 2007-10-01     0.382     0.352 #> 5 2008-01-01     0.800     0.700 #> 6 2008-04-01    -0.200    -0.170 #> 7 2008-07-01    -0.194    NA     #>  #> $US #> # A tibble: 7 × 3 #>   time       release_0 release_1 #>   <date>         <dbl>     <dbl> #> 1 2007-01-01     0.162     0.150 #> 2 2007-04-01     0.974     0.942 #> 3 2007-07-01     1.21      1.20  #> 4 2007-10-01     0.156     0.144 #> 5 2008-01-01     0.224     0.218 #> 6 2008-04-01     0.810     0.699 #> 7 2008-07-01    -0.129    NA # Get the latest release gdp_final <- get_nth_release(gdp_short, n = \"latest\") vintages_wide(gdp_final) #> Warning: Ignoring columns: release #> $EA #> # A tibble: 7 × 2 #>   time       `2008-10-01` #>   <date>            <dbl> #> 1 2007-01-01        0.728 #> 2 2007-04-01        0.477 #> 3 2007-07-01        0.555 #> 4 2007-10-01        0.354 #> 5 2008-01-01        0.661 #> 6 2008-04-01       -0.170 #> 7 2008-07-01       -0.194 #>  #> $US #> # A tibble: 7 × 2 #>   time       `2008-10-01` #>   <date>            <dbl> #> 1 2007-01-01       0.0123 #> 2 2007-04-01       1.18   #> 3 2007-07-01       1.17   #> 4 2007-10-01      -0.0430 #> 5 2008-01-01       0.218  #> 6 2008-04-01       0.699  #> 7 2008-07-01      -0.129 gdp_ea_longer <- gdp %>%    dplyr::filter(id == \"EA\") %>%   ts_pc() %>%    filter(     time >= as.Date(\"2000-01-01\"),     time < as.Date(\"2006-01-01\"),     pub_date >= as.Date(\"2000-01-01\"),     pub_date <= as.Date(\"2006-01-01\")     )  # Get the release from October four years after the initial release gdp_releases <- get_fixed_release(   gdp_ea_longer,    years = 4,    month = \"October\"   ) gdp_releases #> # A tibble: 8 × 4 #>   time       pub_date     value id    #>   <date>     <date>       <dbl> <chr> #> 1 2000-01-01 2004-10-01 0.905   EA    #> 2 2000-04-01 2004-10-01 0.917   EA    #> 3 2000-07-01 2004-10-01 0.387   EA    #> 4 2000-10-01 2004-10-01 0.585   EA    #> 5 2001-01-01 2005-10-01 0.723   EA    #> 6 2001-04-01 2005-10-01 0.131   EA    #> 7 2001-07-01 2005-10-01 0.199   EA    #> 8 2001-10-01 2005-10-01 0.00809 EA"},{"path":"https://p-wegmueller.github.io/reviser/articles/reviser.html","id":"visualizing-vintage-data","dir":"Articles","previous_headings":"","what":"Visualizing Vintage Data","title":"Introduction to reviser","text":"reviser package provides simple flexible tools visualizing real-time vintages. primary function plot_vintages(), supports multiple plot types, including line plots, scatter plots, bar plots, boxplots. returns ggplot2 object, allowing customization ggplot2 package. simple function allowing visualize real-time data lines code. However, possible plot data along one dimension (either pub_date, release id). use plot_vintages(), provide data frame containing: time column (representing observation period), value column (containing reported data), column indicating publication date (pub_date) release number (release), determines dimension along data visualized. example, visualize GDP estimates evolved time, can create line plot comparing different vintages:   default, dim_col (dimension along vintages plotted) contains 30 unique values, recent 30 displayed maintain readability.   customization, can apply custom themes color scales using: scale_color_reviser() scale_fill_reviser() theme_reviser() functions ensure consistent visual style tailored vintage data analysis.","code":"# Line plot showing GDP vintages over the publication date dimension plot_vintages(   gdp_us_short,   title = \"Real-time GDP Estimates for the US\",   subtitle = \"Growth Rate in %\"   ) # Line plot showing GDP vintages over the release dimension gdp_releases <- get_nth_release(gdp_us_short, n = 0:3) plot_vintages(gdp_releases, dim_col = \"release\") # Line plot showing GDP vintages over the publication date dimension plot_vintages(   gdp_ea_longer,   type = \"boxplot\",   title = \"Real-time GDP Estimates for the Euro Area\",   subtitle = \"Growth Rate in %\"   ) # Line plot showing GDP vintages over id dimension plot_vintages(   gdp %>%      ts_pc() %>%      get_latest_release() %>%     na.omit(),    dim_col = \"id\",   title = \"Recent GDP Estimates\",   subtitle = \"Growth Rate in %\"   )"},{"path":"https://p-wegmueller.github.io/reviser/articles/reviser.html","id":"analyzing-data-revisions-and-releases","dir":"Articles","previous_headings":"","what":"Analyzing Data Revisions and Releases","title":"Introduction to reviser","text":"defining final release, can analyze revisions releases multiple ways: Calculate revisions: get_revisions(). See vignette Understanding Data Revisions details. Analyze revisions: get_revision_analysis(). See vignette Revision Patterns Statistics details. Identify first efficient release: get_first_efficient_release(). See vignette Efficient Release Identification details. Nowcast future revisions: kk_nowcast(). See vignette Nowcasting Revisions details.","code":""},{"path":[]},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"revision-size","dir":"Articles","previous_headings":"Summary Statistics","what":"Revision Size","title":"Revision Patterns and Statistics","text":"Revisions provide insights reliability initial data releases. Various metrics assess magnitude distribution:","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"mean-revision-bias-mean","dir":"Articles","previous_headings":"Summary Statistics > Revision Size","what":"1. Mean Revision (\"Bias (mean)\")","title":"Revision Patterns and Statistics","text":"mean revision quantifies systematic bias revisions: Bias=r‾=1N∑t=1Nrtf    \\text{Bias} = \\bar{r} = \\frac{1}{N} \\sum_{t=1}^{N} r_t^{f} mean revision significantly different zero, indicates tendency initial releases systematically - -estimated. t-test conducted test null hypothesis H0:r‾=0H_0: \\bar{r} = 0. \"Bias (p-value)\" reports standard t-test p-value. \"Bias (robust p-value)\" provides heteroskedasticity-robust alternative.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"mean-absolute-revision-mar","dir":"Articles","previous_headings":"Summary Statistics > Revision Size","what":"2. Mean Absolute Revision (\"MAR\")","title":"Revision Patterns and Statistics","text":"mean absolute revision measures average size revisions, regardless direction: MAR=1N∑t=1N|rtf|    \\text{MAR} = \\frac{1}{N} \\sum_{t=1}^{N} |r_t^{f}| metric useful evaluating magnitude revisions rather direction.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"minimum-and-maximum-revisions-minimum-maximum","dir":"Articles","previous_headings":"Summary Statistics > Revision Size","what":"3. Minimum and Maximum Revisions (\"Minimum\", \"Maximum\")","title":"Revision Patterns and Statistics","text":"statistics capture extreme downward upward revisions dataset.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"percentiles-of-revisions-10q-median-90q","dir":"Articles","previous_headings":"Summary Statistics > Revision Size","what":"4. Percentiles of Revisions (\"10Q\", \"Median\", \"90Q\")","title":"Revision Patterns and Statistics","text":"10th, 50th (median), 90th percentiles provide distributional perspective, helping identify skewness tail behavior revisions.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"standard-deviation-of-revisions-std--dev-","dir":"Articles","previous_headings":"Summary Statistics > Revision Size","what":"5. Standard Deviation of Revisions (\"Std. Dev.\")","title":"Revision Patterns and Statistics","text":"standard deviation quantifies dispersion revisions: σr=1N−1∑t=1N(rtf−r‾)2    \\sigma_r = \\sqrt{ \\frac{1}{N-1} \\sum_{t=1}^{N} (r_t^{f} - \\bar{r})^2 } higher standard deviation indicates greater variability revision process.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"noise-to-signal-ratio-noisesignal","dir":"Articles","previous_headings":"Summary Statistics > Revision Size","what":"6. Noise-to-Signal Ratio (\"Noise/Signal\")","title":"Revision Patterns and Statistics","text":"metric measures relative size revisions compared total variance final data: σrσy    \\frac{\\sigma_r}{\\sigma_y} σy\\sigma_y standard deviation final value ytfy_t^f. high noise--signal ratio suggests revisions large relative underlying variability final data, indicating high uncertainty initial estimates.","code":"library(reviser) library(dplyr) library(tsbox)  gdp <- reviser::gdp %>%   ts_pc() %>%   na.omit()  df <- get_nth_release(gdp, 0:1) final_release <- get_latest_release(gdp)  results <- get_revision_analysis(   df,    final_release,   degree = 1   )  head(results) #> # A tibble: 6 × 14 #>   id    release       N `Bias (mean)` `Bias (p-value)` `Bias (robust p-value)` #>   <chr> <chr>     <dbl>         <dbl>            <dbl>                   <dbl> #> 1 CHE   release_0   178       0.110            0.00692                0.000107 #> 2 CHE   release_1   177       0.0960           0.0148                 0.000202 #> 3 EA    release_0   178       0.0553           0.00167                0.000450 #> 4 EA    release_1   177       0.0502           0.00367                0.000673 #> 5 JP    release_0   178       0.00989          0.848                  0.795    #> 6 JP    release_1   177       0.00920          0.859                  0.790    #> # ℹ 8 more variables: Minimum <dbl>, Maximum <dbl>, `10Q` <dbl>, Median <dbl>, #> #   `90Q` <dbl>, MAR <dbl>, `Std. Dev.` <dbl>, `Noise/Signal` <dbl>"},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"correlation-of-revisions","dir":"Articles","previous_headings":"Summary Statistics","what":"Correlation of Revisions","title":"Revision Patterns and Statistics","text":"Understanding revisions relate initial releases past revisions can reveal patterns revision process:","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"correlation-between-revisions-and-initial-releases-correlation","dir":"Articles","previous_headings":"Summary Statistics > Correlation of Revisions","what":"1. Correlation Between Revisions and Initial Releases (\"Correlation\")","title":"Revision Patterns and Statistics","text":"measures whether revisions systematically related initial release ythy_t^h, serves proxy available information time release: ρ=∑(yth−y‾h)(Rrtf−r‾)∑(yth−y‾h)2∑(rtf−r‾)2    \\rho = \\frac{\\sum (y_t^h - \\bar{y}^h) (Rr_t^f - \\bar{r})}{\\sqrt{\\sum (y_t^h - \\bar{y}^h)^2}  \\sqrt{\\sum (r_t^f - \\bar{r})^2}} significant correlation suggests initial estimates contain information predicts later revisions. t-test (\"Correlation (p-value)\") used test whether ρ\\rho significantly different zero.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"st-order-autocorrelation-of-revisions-autocorrelation-1st","dir":"Articles","previous_headings":"Summary Statistics > Correlation of Revisions","what":"2. 1st order Autocorrelation of Revisions (\"Autocorrelation (1st)\")","title":"Revision Patterns and Statistics","text":"first-order autocorrelation measures persistence revision process examining whether past revisions predict future revisions: ρ1=∑(rtf−r‾)(rt−1f−r‾)∑(rtf−r‾)2∑(rt−1f−r‾)2    \\rho_1 = \\frac{\\sum (r_t^f - \\bar{r}) (r_{t-1}^f - \\bar{r})}{\\sqrt{\\sum (r_t^f - \\bar{r})^2 } \\sqrt{\\sum (r_{t-1}^f - \\bar{r})^2}} revisions exhibit strong autocorrelation, may indicate systematic pattern revision process rather purely random adjustments. t-test (\"Autocorrelation (1st p-value)\") used assess whether ρ1\\rho_1 significantly different zero.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"autocorrelation-of-revisions-up-to-1-year-autocorrelation-up-to-1yr-ljung-box-p-value","dir":"Articles","previous_headings":"Summary Statistics > Correlation of Revisions","what":"3. Autocorrelation of Revisions up to 1 year (\"Autocorrelation up to 1yr (Ljung-Box p-value)\")","title":"Revision Patterns and Statistics","text":"metric assesses autocorrelation revisions lag 1 year using Ljung-Box test. null hypothesis Ljung-Box test autocorrelation specified lag. words, revisions independent one another. alternative hypothesis autocorrelation revisions. quarterly data (4 observations per year), test checks autocorrelation 4 lags. monthly data (12 observations per year), test checks autocorrelation 12 lags. frequencies, test skipped. Ljung-Box test statistic computed using following formula: Q=N(N+2)∑k=1mρ̂k2N−k   Q = N(N + 2) \\sum_{k=1}^{m} \\frac{\\hat{\\rho}_k^2}{N - k} QQ Ljung-Box statistic. NN number observations time series. ρ̂k\\hat{\\rho}_k sample autocorrelation lag kk. measures correlation revisions time tt time t−kt-k. mm number lags considered (corresponds frequency data: 4 quarterly data, 12 monthly data). test statistic QQ used determine whether significant autocorrelation. autocorrelation particular lag large, suggests revisions lag independent . larger QQ-statistic, stronger evidence revisions autocorrelated. metrics collectively help evaluate reliability, predictability, potential biases data revisions.","code":"results <- get_revision_analysis(   df,    final_release,   degree = 2   )  head(results) #> # A tibble: 6 × 8 #>   id    release      N Correlation Correlation (p-value…¹ Autocorrelation (1st…² #>   <chr> <chr>    <dbl>       <dbl>                  <dbl>                  <dbl> #> 1 CHE   release…   178      -0.209              0.00517                  -0.0887 #> 2 CHE   release…   177      -0.204              0.00656                  -0.114  #> 3 EA    release…   178      -0.315              0.0000187                -0.0922 #> 4 EA    release…   177      -0.318              0.0000158                -0.157  #> 5 JP    release…   178      -0.204              0.00626                  -0.278  #> 6 JP    release…   177      -0.241              0.00126                  -0.292  #> # ℹ abbreviated names: ¹​`Correlation (p-value)`, ²​`Autocorrelation (1st)` #> # ℹ 2 more variables: `Autocorrelation (1st p-value)` <dbl>, #> #   `Autocorrelation up to 1yr (Ljung-Box p-value)` <dbl>"},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"sign-switches","dir":"Articles","previous_headings":"Summary Statistics","what":"Sign Switches","title":"Revision Patterns and Statistics","text":"Sign switches data revisions can occur direction economic indicator changes initial release later revisions. define two key metrics assess stability directional signals:","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"fraction-of-sign-changes","dir":"Articles","previous_headings":"Summary Statistics > Sign Switches","what":"1. Fraction of sign changes","title":"Revision Patterns and Statistics","text":"metric (\"Fraction correct sign\") evaluates often sign initially reported value ythy_t^h differs final revised value ytfy_t^f. Mathematically, compute: Fraction sign consistency=∑t=1T𝟙(sign(yth)=sign(ytf))T    \\text{Fraction sign consistency} = \\frac{\\sum_{t=1}^{T} \\mathbb{1}(\\text{sign}(y_t^h) = \\text{sign}(y_t^f))}{T} 𝟙(⋅)\\mathbb{1}(\\cdot) indicator function equals 1 signs match 0 otherwise.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"fraction-of-sign-changes-in-the-growth-rate","dir":"Articles","previous_headings":"Summary Statistics > Sign Switches","what":"2. Fraction of sign changes in the growth rate","title":"Revision Patterns and Statistics","text":"metric (\"Fraction correct growth rate change\") assesses whether direction change variable remains consistent revisions. Specifically, compare sign period--period differences: Fraction sign consistency growth=∑t=2T𝟙(sign(Δyth)=sign(Δytf))T−1    \\text{Fraction sign consistency growth} = \\frac{\\sum_{t=2}^{T} \\mathbb{1}(\\text{sign}(\\Delta y_t^h) = \\text{sign}(\\Delta y_t^f))}{T-1} Δyth=yth−yt−1h\\Delta y_t^h = y_t^h - y_{t-1}^h Δytf=ytf−yt−1f\\Delta y_t^f = y_t^f - y_{t-1}^f represent first differences initially reported final values, respectively. high fraction incorrect signs either metric suggests early estimates may unreliable capturing true direction variable.","code":""},{"path":[]},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"news-and-noise-tests-for-data-revisions","dir":"Articles","previous_headings":"Hypothesis Tests","what":"News and Noise Tests for Data Revisions","title":"Revision Patterns and Statistics","text":"news noise tests analyze properties data revisions relation final preliminary releases economic variable. tests help evaluate whether revisions systematic, whether contain new information, whether simply noisy adjustments (Mankiw Shapiro 1986; Aruoba 2008). Final revisions can classified two categories: Noise: initial announcement observation final series, measured error. means revision uncorrelated final value correlated data available estimate made. News: initial announcement efficient forecast reflects available information, subsequent estimates reduce forecast error incorporating new information. revision correlated final value uncorrelated data available estimate made, .e., unpredictable using information set time initial announcement. test categories, run two regression tests:","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"the-noise-test","dir":"Articles","previous_headings":"Hypothesis Tests > News and Noise Tests for Data Revisions","what":"1. The Noise Test","title":"Revision Patterns and Statistics","text":"noise test examines whether revision can predicted final value: rtf=α+β⋅ytf+ϵt   {r}_t^f = \\alpha + \\beta \\cdot {y_t^f} + \\epsilon_t preliminary value efficient unbiased estimate final value (.e incorporating relevant information), revisions uncorrelated final value. null hypothesis : H0:α=0,β=0   H_0: \\alpha = 0, \\quad \\beta = 0 function tests joint hypothesis (\"Noise joint test (p-value)\") α=0\\alpha = 0 β=0\\beta = 0 using heteroskedasticity autocorrelation consistent (HAC) covariance matrix ensure robust inference. α=0\\alpha = 0 tests (\"News test Intercept (p-value)\") whether revisions systematic bias. β=0\\beta = 0 tests (\"News test Coefficient (p-value)\") whether revisions correlated final value, indicating inefficiency.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"the-news-test","dir":"Articles","previous_headings":"Hypothesis Tests > News and Noise Tests for Data Revisions","what":"2. The News Test","title":"Revision Patterns and Statistics","text":"news test examines whether revision predictable using preliminary release: rtf=α+β⋅yth+ϵt {r}_t^f = \\alpha + \\beta \\cdot {y}_t^h + \\epsilon_t , test whether revisions systematically related initial value. null hypothesis : H0:α=0,β=0 H_0: \\alpha = 0, \\quad \\beta = 0 function tests joint hypothesis (\"News joint test (p-value)\") α=0\\alpha = 0 β=0\\beta = 0 using HAC covariance matrix ensure robust inference. α=0\\alpha = 0 tests (\"News test Intercept (p-value)\") whether revisions systematic bias. β=0\\beta = 0 tests (\"News test Coefficient (p-value)\") whether revisions correlated initial value, indicating inefficiency. Note: Instead regressing rtfr_t^f ytfy_t^f ythy_t^h, one can similarly regress $$   \\text{Noise: } \\quad y_t^h = \\alpha + \\beta \\cdot y_t^f + \\epsilon_t \\\\   \\text{News: } \\quad y_t^f = \\alpha + \\beta \\cdot y_t^h + \\epsilon_t $$ test α=0\\alpha = 0 β=1\\beta = 1 presence noise news data revisions.","code":"results <- get_revision_analysis(   df,    final_release,   degree = 3   )  head(results) #> # A tibble: 6 × 17 #>   id    release       N `News test Intercept` `News test Intercept (std.err)` #>   <chr> <chr>     <dbl>                 <dbl>                           <dbl> #> 1 CHE   release_0   178                0.149                           0.0419 #> 2 CHE   release_1   177                0.134                           0.0440 #> 3 EA    release_0   178                0.0741                          0.0195 #> 4 EA    release_1   177                0.0690                          0.0180 #> 5 JP    release_0   178                0.0585                          0.0438 #> 6 JP    release_1   177                0.0650                          0.0407 #> # ℹ 12 more variables: `News test Intercept (p-value)` <dbl>, #> #   `News test Coefficient` <dbl>, `News test Coefficient (std.err)` <dbl>, #> #   `News test Coefficient (p-value)` <dbl>, `News joint test (p-value)` <dbl>, #> #   `Noise test Intercept` <dbl>, `Noise test Intercept (std.err)` <dbl>, #> #   `Noise test Intercept (p-value)` <dbl>, `Noise test Coefficient` <dbl>, #> #   `Noise test Coefficient (std.err)` <dbl>, #> #   `Noise test Coefficient (p-value)` <dbl>, …"},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"test-of-seasonality-in-revisions","dir":"Articles","previous_headings":"Hypothesis Tests","what":"Test of Seasonality in Revisions","title":"Revision Patterns and Statistics","text":"test whether seasonality present revisions, employ Friedman test. Note test always performed first-differentiated series.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"friedman-test","dir":"Articles","previous_headings":"Hypothesis Tests > Test of Seasonality in Revisions","what":"Friedman Test","title":"Revision Patterns and Statistics","text":"Friedman test (\"Seasonality (Friedman p-value)\") non-parametric statistical test examines whether distribution ranked data differs systematically across seasonal periods, months quarters. require distributional assumptions, making robust tool detecting seasonality revision series. test applied first transforming revision series matrix row represents year column represents specific month quarter. constructed follows. Consider first matrix data {xij}n×k\\{x_{ij}\\}_{n \\times k} nn rows (.e., number years sample) kk columns (.e., either 12 months 4 quarters, depending frequency data). data matrix needs replaced new matrix {rij}n×k\\{r_{ij}\\}_{n \\times k}, entry rijr_{ij} rank xijx_{ij} within row ii. test executed using stats::friedman.test() function. null hypothesis average ranking across columns , indicating seasonality revisions.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"theils-u-statistics","dir":"Articles","previous_headings":"Hypothesis Tests","what":"Theil’s U Statistics","title":"Revision Patterns and Statistics","text":"context revision analysis, Theil’s inequality coefficient, Theil’s U, provides measure accuracy initial estimates (ythy_t^h) relative final refined values (ytfy_t^f). Various definitions Theil’s statistics exist, leading different interpretations. package considers two widely used variants: U1 U2.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"theils-u1-statistic-theils-u1","dir":"Articles","previous_headings":"Hypothesis Tests > Theil’s U Statistics","what":"1. Theil’s U1 Statistic (\"Theil's U1\")","title":"Revision Patterns and Statistics","text":"first measure, U1, given : U1=1n∑t=1n(ytf−yth)21n∑t=1nytf2+1n∑t=1nyth2 U_1 = \\frac{\\sqrt{\\frac{1}{n}\\sum^n_{t=1}(y_t^f-y_t^h)^2}}{\\sqrt{\\frac{1}{n}\\sum^n_{t=1}{y_t^f}^2}+\\sqrt{\\frac{1}{n}\\sum^n_{t=1}{y_t^h}^2}} U1 statistic bounded 0 1: value 0 implies perfect forecasting (yth=ytfy_t^h = y_t^f tt). value closer 1 indicates lower accuracy. However, U1 suffers several limitations, highlighted Granger Newbold (1973). critical issue arises one ythy_t^h ytfy_t^f equals zero periods. cases, denominator numerator become equal, leading U1 = 1 even preliminary estimates close final values.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/revision-analysis.html","id":"theils-u2-statistic-theils-u2","dir":"Articles","previous_headings":"Hypothesis Tests > Theil’s U Statistics","what":"2. Theil’s U2 Statistic (\"Theil's U2\")","title":"Revision Patterns and Statistics","text":"address shortcomings, Theil et al. (1966) proposed alternative measure, U2, defined : U2=∑t=1n(yt+1h−yt+1fYtf)2∑t=1n(yt+1f−ytfYtf)2 U_2 = \\frac{\\sqrt{\\sum_{t=1}^{n} \\left( \\frac{y_{t+1}^h- y_{t+1}^f}{Y_t^f} \\right)^2}}{\\sqrt{\\sum_{t=1}^{n} \\left( \\frac{y_{t+1}^f - y_t^f}{Y_t^f} \\right)^2}} : numerator captures relative errors preliminary estimates. denominator measures magnitude changes final values time. Unlike U1, U2 bounded 0 1. Instead: value 0 implies perfect accuracy (yth=ytfy_{t}^h = y_{t}^f tt). U2=1U_2 = 1 means accuracy preliminary estimates equal naïve forecast. U2>1U_2 > 1 suggests preliminary estimates less accurate naïve approach. U2<1U_2 < 1 indicates preliminary estimates accurate naïve method. Whenever possible (ytf≠0y_{t}^f \\neq 0 tt), U2 preferred metric evaluating preliminary estimates. examples, analyze GDP revisions comparing final release first second releases, correspond diagonal elements real-time data matrix. approach provides insight initial estimates evolve time. Alternatively, can compare GDP revisions specific publication dates. example , analyze revisions GDP releases April July 2024, using final release October 2024 benchmark. grouping statistics default determined pub_date release column. Alternatively, can specified via optional function argument grouping_var. get_revision_analysis() function requires single time series final_release compares multiple time series df id. always compare two consecutive publication dates, necessary structure analysis sequentially. code iterates consecutive publication dates gdp dataset, comparing revisions pair. pair consecutive dates, extracts corresponding data, runs get_revision_analysis() analyze revisions, combines results single dataframe.","code":"results <- get_revision_analysis(   df,    final_release,   degree = 4   )  head(results) #> # A tibble: 6 × 8 #>   id    release     N Fraction of correct …¹ Fraction of correct …² `Theil's U1` #>   <chr> <chr>   <dbl>                  <dbl>                  <dbl>        <dbl> #> 1 CHE   releas…   178                  0.803                  0.652       0.262  #> 2 CHE   releas…   177                  0.802                  0.644       0.250  #> 3 EA    releas…   178                  0.944                  0.764       0.0818 #> 4 EA    releas…   177                  0.944                  0.763       0.0797 #> 5 JP    releas…   178                  0.820                  0.725       0.266  #> 6 JP    releas…   177                  0.802                  0.712       0.262  #> # ℹ abbreviated names: ¹​`Fraction of correct sign`, #> #   ²​`Fraction of correct growth rate change` #> # ℹ 2 more variables: `Theil's U2` <dbl>, #> #   `Seasonality (Friedman p-value)` <dbl> df <- gdp %>%   filter(pub_date %in% c(\"2024-04-01\", \"2024-07-01\"))   results <- get_revision_analysis(   df,    final_release,   degree = 5   )  head(results) #> # A tibble: 6 × 39 #>   id    pub_date       N Frequency `Bias (mean)` `Bias (p-value)` #>   <chr> <date>     <dbl>     <dbl>         <dbl>            <dbl> #> 1 CHE   2024-04-01   176         4       0.00226            0.478 #> 2 CHE   2024-07-01   177         4      -0.00123            0.371 #> 3 EA    2024-04-01   176         4       0.00656            0.159 #> 4 EA    2024-07-01   177         4       0.00205            0.520 #> 5 JP    2024-04-01   176         4      -0.00323            0.490 #> 6 JP    2024-07-01   177         4      -0.00276            0.305 #> # ℹ 33 more variables: `Bias (robust p-value)` <dbl>, Minimum <dbl>, #> #   Maximum <dbl>, `10Q` <dbl>, Median <dbl>, `90Q` <dbl>, MAR <dbl>, #> #   `Std. Dev.` <dbl>, `Noise/Signal` <dbl>, Correlation <dbl>, #> #   `Correlation (p-value)` <dbl>, `Autocorrelation (1st)` <dbl>, #> #   `Autocorrelation (1st p-value)` <dbl>, #> #   `Autocorrelation up to 1yr (Ljung-Box p-value)` <dbl>, `Theil's U1` <dbl>, #> #   `Theil's U2` <dbl>, `Seasonality (Friedman p-value)` <dbl>, … # Get unique sorted publication dates pub_dates <- gdp %>%   distinct(pub_date) %>%   arrange(pub_date) %>%   pull(pub_date)  # Run the function for each pair of consecutive publication dates results <- purrr::map_dfr(seq_along(pub_dates[-length(pub_dates)]), function(i) {      df <- gdp %>%     filter(pub_date %in% pub_dates[i])      final_release <- gdp %>%     filter(pub_date %in% pub_dates[i + 1])      get_revision_analysis(df, final_release, degree = 5) })  head(results) #> # A tibble: 6 × 39 #>   id    pub_date       N Frequency `Bias (mean)` `Bias (p-value)` #>   <chr> <date>     <dbl>     <dbl>         <dbl>            <dbl> #> 1 CHE   2002-10-01    90         4      0.000632            0.634 #> 2 EA    2002-10-01    90         4      0.00106             0.512 #> 3 JP    2002-10-01    90         4      0.0231              0.629 #> 4 US    2002-10-01    90         4      0                 NaN     #> 5 CHE   2003-01-01    91         4     -0.00384             0.563 #> 6 EA    2003-01-01    91         4      0.00192             0.750 #> # ℹ 33 more variables: `Bias (robust p-value)` <dbl>, Minimum <dbl>, #> #   Maximum <dbl>, `10Q` <dbl>, Median <dbl>, `90Q` <dbl>, MAR <dbl>, #> #   `Std. Dev.` <dbl>, `Noise/Signal` <dbl>, Correlation <dbl>, #> #   `Correlation (p-value)` <dbl>, `Autocorrelation (1st)` <dbl>, #> #   `Autocorrelation (1st p-value)` <dbl>, #> #   `Autocorrelation up to 1yr (Ljung-Box p-value)` <dbl>, `Theil's U1` <dbl>, #> #   `Theil's U2` <dbl>, `Seasonality (Friedman p-value)` <dbl>, …"},{"path":[]},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"introduction-why-do-data-revisions-occur","dir":"Articles","previous_headings":"","what":"Introduction: Why do data revisions occur?","title":"Understanding Data Revisions","text":"Economic statistical data, particular time series data, frequently revised initial publication. revisions occur due variety reasons, including methodological updates, newly available data, technical adjustments. Understanding revisions happen crucial properly interpreting economic indicators assessing data reliability. Revisions can classified several key categories:","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"incorporation-of-newly-available-or-updated-data","dir":"Articles","previous_headings":"Introduction: Why do data revisions occur?","what":"Incorporation of newly available or updated data","title":"Understanding Data Revisions","text":"Initial estimates economic indicators often based partial preliminary data. comprehensive information becomes available, statistical agencies revise figures reflect accurate representation economic activity. common GDP estimates, labor statistics, lesser extent also inflation measures. Many statistical agencies use interpolation extrapolation techniques estimate quarterly indicators based incomplete information. new input data becomes available, past estimates revised align improved dataset (Sax Steiner 2013). Example: U.S. Bureau Economic Analysis (BEA) revises GDP estimates multiple times data becomes available.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"base-data-revisions","dir":"Articles","previous_headings":"Introduction: Why do data revisions occur?","what":"Base data revisions","title":"Understanding Data Revisions","text":"Annual macroeconomic data, national accounts GDP, often revised new yearly aggregates released. Statistical offices typically revise figures recent two three years, older data remains unchanged unless major methodological update. Example: Swiss Federal Statistical Office (SFSO) revises past two years annual GDP August.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"benchmark-revisions-methodological-changes","dir":"Articles","previous_headings":"Introduction: Why do data revisions occur?","what":"Benchmark revisions (methodological changes)","title":"Understanding Data Revisions","text":"Concepts methodologies used national accounts evolve time comply new international standards improve accuracy. Benchmark revisions introduce major changes may affect entire historical time series. Examples benchmark revisions Swiss GDP measurement: revisions can significantly alter growth rates, levels, historical trends.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"minor-changes-in-estimation-methods","dir":"Articles","previous_headings":"Introduction: Why do data revisions occur?","what":"Minor changes in estimation methods","title":"Understanding Data Revisions","text":"Even large-scale benchmark revisions occur, statistical agencies continuously refine estimation methods: Adjustments seasonal adjustment techniques. Replacing outdated indicators new ones. Improving econometric models nowcasting forecasting. Example: Changes consumer confidence indexes incorporated GDP forecasts.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"technical-adjustments-error-corrections","dir":"Articles","previous_headings":"Introduction: Why do data revisions occur?","what":"Technical adjustments & error corrections","title":"Understanding Data Revisions","text":"Revisions can occur due simple technical adjustments, including: Correction data entry errors. Adjustments due missing late-reported data. Revisions survey weighting methods. Example: Bureau Labor Statistics (BLS) revises employment data late reports firms incorporated.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"economic-events-shocks","dir":"Articles","previous_headings":"Introduction: Why do data revisions occur?","what":"Economic events & shocks","title":"Understanding Data Revisions","text":"Unforeseen economic events often require large-scale revisions due structural breaks economic activity. Examples: COVID-19 pandemic: GDP estimates revised significantly lockdowns disrupted economic data collection. Financial crises: Banking sector collapses lead re-evaluation past financial statistics. events create higher--normal uncertainty, necessitating frequent revisions.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"technological-advances-in-data-collection","dir":"Articles","previous_headings":"Introduction: Why do data revisions occur?","what":"Technological advances in data collection","title":"Understanding Data Revisions","text":"adoption big data, machine learning, AI economic statistics introduced new ways process analyze data. technological advances can lead revisions agencies shift sophisticated data integration methods. Example: Nowcasting models using high-frequency data (e.g., credit card transactions) influence revisions real-time GDP estimates.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"some-mathematical-notation","dir":"Articles","previous_headings":"Introduction: Why do data revisions occur?","what":"Some mathematical notation","title":"Understanding Data Revisions","text":"notation follows standard conventions literature: Superscripts (vintage) refer estimate available. Subscripts (time) refer observation recorded. example: \\( y_1^t \\) estimate available time \\( t \\) value variable \\( y \\) time 1. general: \\( y_j^t \\) represents estimate \\( y \\) time \\( j \\), released vintage \\( t \\). Revisions often studied form revision triangle, : \\[ Y = \\begin{bmatrix} y_1^1 & & y_1^{t-l} & & y_1^t \\\\ & \\ddots & \\vdots & \\vdots & \\vdots \\\\ & & y_{t-l}^{t-l} & \\cdots & y_{t-l}^t \\\\ & & & \\ddots & \\vdots \\\\ & & & & y_t^t \\\\ \\end{bmatrix} \\] row corresponds specific time period column corresponds successive release data. move rightward, see later vintages (updated data releases).move downward, observe later time periods.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"extracting-revisions-with-reviser","dir":"Articles","previous_headings":"","what":"Extracting revisions with reviser","title":"Understanding Data Revisions","text":"Now understand revisions occur, next step quantify analyze . economic statistics, real-time data consists multiple vintages observations, vintage represents successive release data. vintages stored revision triangle, also known real-time data matrix, : Rows represent time periods original observations. Columns represent successive vintages (releases) data.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"the-get_revisions-function","dir":"Articles","previous_headings":"Extracting revisions with reviser","what":"The get_revisions() function","title":"Understanding Data Revisions","text":"data scrutiny formatted along lines illustrated introduction reviser, .e., long tidy format data tibble consists : time, time period pub_date /release, publication date release number value, reported value. id, optional column distinguish different series can extract revisions inherent time series vintages function get_revisions(). function allows users compute revisions comparing different vintages time series dataset. supports three primary methods: Fixed Reference Date (ref_date): Computes revisions relative fixed publication date. Nth Release (nth_release): Compares revisions nth release data point. Interval Lag (interval): Measures changes vintages published fixed number periods apart.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"example-usage","dir":"Articles","previous_headings":"Extracting revisions with reviser","what":"Example usage","title":"Understanding Data Revisions","text":"formatted dataset appropriate long tidy format, can apply get_revisions() function analyze revisions using different methods. practical examples using GDP revision data.","code":""},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"example-1-revisions-using-an-interval","dir":"Articles","previous_headings":"Extracting revisions with reviser > Example usage","what":"Example 1: Revisions Using an Interval","title":"Understanding Data Revisions","text":"common use case analyze reported values evolve time. setting interval = 1, compute revisions consecutive releases:   helps identify patterns data revised time, whether revisions systematic random, magnitude.","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(reviser) library(tsbox)  # Example dataset gdp <- reviser::gdp %>%   ts_pc() %>%   na.omit()  revisions_interval <- get_revisions(gdp, interval = 1)  # Preview results # How do the 2nd and 3rd release revise compared to previous quarter? plot_vintages(   revisions_interval %>%      filter(id == \"US\") %>%     get_nth_release(1:2),   dim_col = \"release\",   title = \"Revisions of 2nd (release_1) and 3rd (release_2) release\",   subtitle = \"For the US\" ) # Revisions of the latest release plot_vintages(   revisions_interval %>% get_latest_release(),   dim_col = \"id\",   title = \"Revisions of the latest release\",   subtitle = \"For several countries\" ) #> Warning: Removed 4 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"example-2-revisions-relative-to-a-fixed-reference-date","dir":"Articles","previous_headings":"Extracting revisions with reviser > Example usage","what":"Example 2: Revisions Relative to a Fixed Reference Date","title":"Understanding Data Revisions","text":"compare reported values fixed publication date, use ref_date argument. useful benchmarking initial estimate:","code":"revisions_date <- get_revisions(gdp, ref_date = as.Date(\"2005-10-01\"))  # Preview results # Revisions of the latest release plot_vintages(   revisions_date %>% get_latest_release(),   dim_col = \"id\",   title = \"Revisions of the latest release compared to Q4 2005\",   subtitle = \"For several countries\",   type=\"bar\" )"},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"example-3-revisions-to-the-nth-release","dir":"Articles","previous_headings":"Extracting revisions with reviser > Example usage","what":"Example 3: Revisions to the Nth Release","title":"Understanding Data Revisions","text":"Instead comparing consecutive releases, can compare data point nth release. example, want evaluate revisions first last releases:","code":"revisions_nth <- get_revisions(gdp, nth_release = 0)  # Preview results # Revisions of the latest release plot_vintages(   revisions_nth %>% get_latest_release(),   dim_col = \"id\",   title = \"Revisions of the latest compared to first release\",   subtitle = \"For several countries\",   type=\"bar\" )"},{"path":"https://p-wegmueller.github.io/reviser/articles/understanding-revisions.html","id":"example-4-how-does-the-growth-rate-of-gdp-change-over-time","dir":"Articles","previous_headings":"Extracting revisions with reviser > Example usage","what":"Example 4: How does the growth rate of GDP change over time?","title":"Understanding Data Revisions","text":"","code":"growthrates_q405 <- get_releases_by_date(gdp, as.Date(\"2005-10-01\"))     # Preview results plot_vintages(   growthrates_q405,   dim_col = \"id\",   time_col = \"pub_date\",   title = \"Evolution of growth rates for GDP Q4 2005\",   subtitle = \"For several countries\",   type=\"line\" )"},{"path":"https://p-wegmueller.github.io/reviser/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Marc Burri. Author, maintainer, copyright holder. Philipp Wegmueller. Author, copyright holder.","code":""},{"path":"https://p-wegmueller.github.io/reviser/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Burri M, Wegmueller P (2025). reviser: Tools Studying Revision Properties Real-Time Time Series Vintages. R package version 0.1.0.9000, https://p-wegmueller.github.io/reviser/.","code":"@Manual{,   title = {reviser: Tools for Studying Revision Properties in Real-Time Time Series Vintages},   author = {Marc Burri and Philipp Wegmueller},   year = {2025},   note = {R package version 0.1.0.9000},   url = {https://p-wegmueller.github.io/reviser/}, }"},{"path":"https://p-wegmueller.github.io/reviser/index.html","id":"reviser-","dir":"","previous_headings":"","what":"Tools for Studying Revision Properties in Real-Time Time Series Vintages","title":"Tools for Studying Revision Properties in Real-Time Time Series Vintages","text":"reviser R package designed working time-series vintages data. package provides tools clean, visualize, analyze time-series revisions.","code":""},{"path":"https://p-wegmueller.github.io/reviser/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools for Studying Revision Properties in Real-Time Time Series Vintages","text":"can install development version reviser GitHub :","code":"# Install devtools if not already installed # install.packages(\"devtools\")  # Install the reviser package devtools::install_github(\"p-wegmueller/reviser\")"},{"path":"https://p-wegmueller.github.io/reviser/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Tools for Studying Revision Properties in Real-Time Time Series Vintages","text":"","code":"library(reviser) suppressMessages(library(dplyr))  gdp <- gdp %>%    filter(id == \"US\") %>%   tsbox::ts_pc() %>%    tsbox::ts_span(start = \"1980-01-01\")  gdp_wide <- vintages_wide(gdp)  gdp_long <- vintages_long(gdp_wide, keep_na = FALSE)  plot_vintages(   gdp_long %>%    filter(     pub_date >= as.Date(\"2009-01-01\") & pub_date < as.Date(\"2010-01-01\"),     time < as.Date(\"2010-01-01\") & time > as.Date(\"2008-01-01\")     ),   type = \"line\",   title = \"Revisions of GDP during the financial crisis\",   subtitle = \"qoq growth rates\") final_release <- get_nth_release(gdp_long, n = 16)  df <- get_nth_release(gdp_long, n = 0:6)  summary <- get_revision_analysis(df, final_release) #> Warning: Both 'release' and 'pub_date' columns are present in 'df. The #> 'release' column will be used. print(summary) #> # A tibble: 7 × 12 #>   id    release       N `Bias (mean)` `Bias (p-value)` Minimum Maximum    MAR #>   <chr> <chr>     <dbl>         <dbl>            <dbl>   <dbl>   <dbl>  <dbl> #> 1 US    release_0   154       -0.0296          0.162    -0.844   1.01  0.188  #> 2 US    release_1   154       -0.0304          0.133    -0.801   0.706 0.186  #> 3 US    release_2   154       -0.0287          0.161    -0.930   0.706 0.185  #> 4 US    release_3   154       -0.0259          0.118    -0.930   0.662 0.111  #> 5 US    release_4   154       -0.0290          0.0654   -0.930   0.662 0.103  #> 6 US    release_5   154       -0.0363          0.0101   -0.930   0.468 0.0919 #> 7 US    release_6   154       -0.0336          0.00369  -0.574   0.359 0.0735 #> # ℹ 4 more variables: `Std. Dev.` <dbl>, `Noise/Signal` <dbl>, #> #   Correlation <dbl>, `Correlation (p-value)` <dbl> efficient_release <- get_first_efficient_release(df, final_release) summary(efficient_release) #> Efficient release:  0  #>  #> Model summary:  #>  #> Call: #> stats::lm(formula = formula, data = df_wide) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -0.82139 -0.12266  0.04048  0.13457  1.00888  #>  #> Coefficients: #>              Estimate Std. Error t value Pr(>|t|)     #> (Intercept) -0.005314   0.029173  -0.182    0.856     #> release_0    0.963024   0.030626  31.445   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.2617 on 152 degrees of freedom #>   (16 observations deleted due to missingness) #> Multiple R-squared:  0.8668, Adjusted R-squared:  0.8659  #> F-statistic: 988.8 on 1 and 152 DF,  p-value: < 2.2e-16 #>  #>  #> Test summary:  #> Linear hypothesis test #>  #> Hypothesis: #> (Intercept) = 0 #> release_0 = 1 #>  #> Model 1: restricted model #> Model 2: final ~ release_0 #>  #> Note: Coefficient covariance matrix supplied. #>  #>   Res.Df Df      F  Pr(>F)   #> 1    154                     #> 2    152  2 2.4805 0.08708 . #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://p-wegmueller.github.io/reviser/reference/fetch_alfred_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Real-Time Data from ALFRED and Format for ReviseR — fetch_alfred_data","title":"Download Real-Time Data from ALFRED and Format for ReviseR — fetch_alfred_data","text":"function retrieves real-time data Federal Reserve Bank St. Louis ALFRED database formats tidy structure suitable analysis ReviseR package.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/fetch_alfred_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Real-Time Data from ALFRED and Format for ReviseR — fetch_alfred_data","text":"","code":"fetch_alfred_data(   series_id,   series_name = NULL,   observation_start = \"1995-01-01\",   observation_end = \"2024-12-01\",   realtime_start = \"2015-01-01\",   realtime_end = \"2022-01-01\",   api_key = NULL )"},{"path":"https://p-wegmueller.github.io/reviser/reference/fetch_alfred_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Real-Time Data from ALFRED and Format for ReviseR — fetch_alfred_data","text":"series_id character vector specifying one ALFRED series IDs (e.g., c(\"CPIAUCSL\", \"PCEPI\")). series_name character vector specifying custom names series (defaults series_id). observation_start character string specifying start date observations (format: \"YYYY-MM-DD\"). observation_end character string specifying end date observations (format: \"YYYY-MM-DD\"). realtime_start character string specifying start date real-time vintages (format: \"YYYY-MM-DD\"). realtime_end character string specifying end date real-time vintages (format: \"YYYY-MM-DD\"). api_key character string containing valid ALFRED API key (optional, defaults NULL).","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/fetch_alfred_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Real-Time Data from ALFRED and Format for ReviseR — fetch_alfred_data","text":"tibble following columns: ref_date: reference date (actual time observation). pub_date: publication date vintage (real-time data release date). id: series identifier (series_name provided, otherwise series_id). value: reported value given observation vintage.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/fetch_alfred_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Real-Time Data from ALFRED and Format for ReviseR — fetch_alfred_data","text":"","code":"# Fetch real-time CPI and PCE data from ALFRED data <- fetch_alfred_data(   series_id = c(\"CPIAUCSL\", \"PCEPI\"),   series_name = c(\"cpi\", \"pce\"),   observation_start = \"1975-01-01\",   observation_end = \"2024-01-31\",   realtime_start = \"2000-01-01\",   realtime_end = \"2024-01-31\" ) #> Warning: There was 1 warning in `mutate()`. #> ℹ In argument: `name = as.numeric(.data$name)`. #> Caused by warning: #> ! NAs introduced by coercion  head(data) #> # A tibble: 6 × 4 #>   time       pub_date   id    value #>   <date>     <date>     <chr> <dbl> #> 1 1975-01-01 2000-01-01 cpi    52.3 #> 2 1975-02-01 2000-01-01 cpi    52.6 #> 3 1975-03-01 2000-01-01 cpi    52.8 #> 4 1975-04-01 2000-01-01 cpi    53   #> 5 1975-05-01 2000-01-01 cpi    53.1 #> 6 1975-06-01 2000-01-01 cpi    53.5"},{"path":"https://p-wegmueller.github.io/reviser/reference/gdp.html","id":null,"dir":"Reference","previous_headings":"","what":"Vintages Data — gdp","title":"Vintages Data — gdp","text":"collection real-time datasets.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/gdp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vintages Data — gdp","text":"","code":"gdp"},{"path":"https://p-wegmueller.github.io/reviser/reference/gdp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Vintages Data — gdp","text":"gdp: Quarterly Vintages (Billions real dollars, seasonally adjusted) Timeframe: Q1 1980 - Q4 2024 Real-Time Vintages: Q4 2002 - Q4 2024 Frequency: Quarterly Format: tibble quarterly observations 3 variables: time: Date observation. pub_date: Publication date vintage values: Numeric, real GDP (seasonally adjusted). id: Country code","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/gdp.html","id":"sources","dir":"Reference","previous_headings":"","what":"Sources","title":"Vintages Data — gdp","text":"data taken realtime database Indergand Leist (2014). Countries: CHE: Switzerland Source: SECO US: United States Sources: FRED, OECD EA: Euro Area Sources: Eurostat, OECD JP: Japan Sources: Cabinet Office (Japan), OECD","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/gdp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Vintages Data — gdp","text":"Indergand, R., Leist, S. Real-Time Data Set Switzerland. Swiss J Economics Statistics 150, 331–352 (2014). https://doi.org/10.1007/BF03399410","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/gdp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vintages Data — gdp","text":"","code":"# Load [gdp] dataset data(gdp)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_days_to_release.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the Number of Days Between Period End and First Release — get_days_to_release","title":"Calculate the Number of Days Between Period End and First Release — get_days_to_release","text":"Computes number days publication date (pub_date) release time period (time) end date record dataset.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_days_to_release.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the Number of Days Between Period End and First Release — get_days_to_release","text":"","code":"get_days_to_release(df)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_days_to_release.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the Number of Days Between Period End and First Release — get_days_to_release","text":"df data frame containing data vintages. data frame must include columns pub_date (publication date release) time (corresponding time period data).","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_days_to_release.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the Number of Days Between Period End and First Release — get_days_to_release","text":"data frame additional column days_to_release representing number days publication date (pub_date) time period (time) release.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_days_to_release.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the Number of Days Between Period End and First Release — get_days_to_release","text":"function calculates difference pub_date time row dataset. result expressed number days release publication date corresponding time period end. dataset wide format, first transformed long format using vintages_long.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_days_to_release.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the Number of Days Between Period End and First Release — get_days_to_release","text":"","code":"# Example data df <- dplyr::filter(reviser::gdp, id==\"US\")  # Calculate days to release df_with_days <- get_days_to_release(df)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_first_efficient_release.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify the First Efficient Release in Vintage Data — get_first_efficient_release","title":"Identify the First Efficient Release in Vintage Data — get_first_efficient_release","text":"Identifies first release sequence vintages \"efficient\" relative final release. release deemed efficient satisfies specific conditions unbiasedness efficiency, tested using Mincer-Zarnowitz type linear regression hypothesis testing.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_first_efficient_release.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify the First Efficient Release in Vintage Data — get_first_efficient_release","text":"","code":"get_first_efficient_release(   df,   final_release,   significance = 0.05,   test_all = FALSE )"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_first_efficient_release.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify the First Efficient Release in Vintage Data — get_first_efficient_release","text":"df data frame class tbl_release containing vintage data. must include columns: time: reference period (e.g., quarter month). value: observed value given release. release: release number identifier. final_release data frame containing final release data. must include columns: time: reference period. value: observed final value given period. significance numeric value specifying significance level hypothesis test (default 0.05). test_all logical value indicating whether test releases, even finding first efficient release (default FALSE).","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_first_efficient_release.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify the First Efficient Release in Vintage Data — get_first_efficient_release","text":"list class list_eff_rel following elements: e: index first efficient release. (0 indexed) data: long-format data frame containing vintage data final release appended. models: list linear regression models fitted release. tests: list hypothesis test results release.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_first_efficient_release.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify the First Efficient Release in Vintage Data — get_first_efficient_release","text":"function performs following steps: Validates inputs ensures df final_release correct format. Iteratively tests release efficiency using linear regression model form: $$final = \\beta_0 + \\beta_1 \\cdot release_i + \\epsilon$$ null hypothesis efficiency : \\(\\beta_0 = 0\\) (bias) \\(\\beta_1 = 1\\) (efficiency) Uses heteroskedasticity autocorrelation consistent (HAC) standard errors robust hypothesis testing. Stops testing first efficient release found (unless test_all = TRUE). efficient release found, warning issued.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_first_efficient_release.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify the First Efficient Release in Vintage Data — get_first_efficient_release","text":"","code":"# Example data df <- get_nth_release(tsbox::ts_pc(dplyr::filter(reviser::gdp, id==\"US\")), n = 0:3)  final_release <- get_nth_release(tsbox::ts_pc(dplyr::filter(reviser::gdp, id==\"US\")), n = 10)  # Identify the first efficient release result <- get_first_efficient_release(df, final_release, significance = 0.05)  # Access the index of the first efficient release result$e #> [1] 0"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_first_release.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the First Data Release (Vintage) — get_first_release","title":"Extract the First Data Release (Vintage) — get_first_release","text":"Filters input dataset return earliest release (vintage) time period.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_first_release.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the First Data Release (Vintage) — get_first_release","text":"","code":"get_first_release(df, diagonal = FALSE)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_first_release.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the First Data Release (Vintage) — get_first_release","text":"df data frame containing data vintages. data frame must include columns pub_date (publication date release) time (corresponding time period data). diagonal Logical. TRUE, function returns real first releases.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_first_release.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the First Data Release (Vintage) — get_first_release","text":"filtered data frame containing first release(s). resulting data frame assigned class tbl_release indicate structure.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_first_release.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract the First Data Release (Vintage) — get_first_release","text":"time period, function identifies release earliest publication date (pub_date). new column release added labels rows resulting data frame release_0. diagonal set TRUE, function returns real first releases. historic values vintages exist returned.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_first_release.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the First Data Release (Vintage) — get_first_release","text":"","code":"# Example data df <- dplyr::filter(reviser::gdp, id==\"US\")  # Get the first release for each time period first_release <- get_first_release(df)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_fixed_release.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Vintage Values from a Data Frame — get_fixed_release","title":"Extract Vintage Values from a Data Frame — get_fixed_release","text":"statistical agencies make final revision data certain period time give month year. function extracts values given month quarter specified  number years initial release.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_fixed_release.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Vintage Values from a Data Frame — get_fixed_release","text":"","code":"get_fixed_release(df, years, month = NULL, quarter = NULL)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_fixed_release.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Vintage Values from a Data Frame — get_fixed_release","text":"df data frame containing columns pub_date (publication date) time (observation date). years number years pub_date values extracted. month optional parameter specifying target month name (\"July\") integer (7). used quarter. quarter optional parameter specifying target quarter (1-4). used month.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_fixed_release.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Vintage Values from a Data Frame — get_fixed_release","text":"filtered data frame containing values matching specified criteria.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_fixed_release.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Vintage Values from a Data Frame — get_fixed_release","text":"","code":"df <- dplyr::filter(reviser::gdp, id==\"US\") dta <- get_fixed_release(df, month = \"July\", years = 3) dta <- get_fixed_release(df, month = 7, years = 3) dta <- get_fixed_release(df, quarter = 3, years = 3)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_latest_release.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the Latest Data Release (Vintage) — get_latest_release","title":"Extract the Latest Data Release (Vintage) — get_latest_release","text":"Filters input dataset return recent release (vintage) time period.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_latest_release.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the Latest Data Release (Vintage) — get_latest_release","text":"","code":"get_latest_release(df)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_latest_release.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the Latest Data Release (Vintage) — get_latest_release","text":"df data frame containing data vintages. data frame must include columns pub_date (publication date release) time (corresponding time period data).","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_latest_release.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the Latest Data Release (Vintage) — get_latest_release","text":"filtered data frame containing recent release(s). resulting data frame assigned class tbl_release indicate structure.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_latest_release.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract the Latest Data Release (Vintage) — get_latest_release","text":"time period, function identifies release latest publication date (pub_date) adds column release labels release release_N, N release index (zero indexed).","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_latest_release.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the Latest Data Release (Vintage) — get_latest_release","text":"","code":"# Example data df <- dplyr::filter(reviser::gdp, id==\"US\")  # Get the latest release for each time period latest_release <- get_latest_release(df)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_nth_release.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the Nth Data Release (Vintage) — get_nth_release","title":"Extract the Nth Data Release (Vintage) — get_nth_release","text":"Filters input dataset return Nth release (vintage) data time period. function supports selecting first, latest, specific numbered release.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_nth_release.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the Nth Data Release (Vintage) — get_nth_release","text":"","code":"get_nth_release(df, n = 0, diagonal = FALSE)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_nth_release.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the Nth Data Release (Vintage) — get_nth_release","text":"df data frame containing data vintages. data frame must include columns pub_date (publication date release) time (corresponding time period data). n release number extract. Accepts: - positive integer vector (e.g., 1 first release, 2 second, etc.). - \"first\" extract first release. - \"latest\" extract recent release. Default 1 (first release). diagonal Logical. TRUE, function returns real first releases.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_nth_release.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the Nth Data Release (Vintage) — get_nth_release","text":"filtered data frame containing specified release(s). resulting data frame assigned class tbl_release indicate structure. diagonal set TRUE, function returns real first releases. historic values vintages exist returned.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_nth_release.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract the Nth Data Release (Vintage) — get_nth_release","text":"behavior depends value n: Non-negative integer: function retrieves Nth release time period (e.g., 0 = first release, 1 = second release, etc.). \"first\": Retrieves first release time period (via get_first_release). \"latest\": Retrieves recent release time period (via get_latest_release).","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_nth_release.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the Nth Data Release (Vintage) — get_nth_release","text":"","code":"# Example data df <- dplyr::filter(reviser::gdp, id==\"US\")  # Get the first release (n = 0) first_release <- get_nth_release(df, n = 0)  # Get the latest release latest_release <- get_nth_release(df, n = \"latest\")  # Get the second release (n = 1) second_release <- get_nth_release(df, n = 1)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_releases_by_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Data Releases for a Specific Date — get_releases_by_date","title":"Get Data Releases for a Specific Date — get_releases_by_date","text":"Filters input dataset return releases corresponding specific time period (date).","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_releases_by_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Data Releases for a Specific Date — get_releases_by_date","text":"","code":"get_releases_by_date(df, date)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_releases_by_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Data Releases for a Specific Date — get_releases_by_date","text":"df data frame containing data vintages. data frame must include columns pub_date (publication date release) time (corresponding time period data). date Date object specifying time period (date) releases retrieved.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_releases_by_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Data Releases for a Specific Date — get_releases_by_date","text":"data frame containing releases specified date. returned data frame include structure input, filtered include rows matching date time column.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_releases_by_date.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Data Releases for a Specific Date — get_releases_by_date","text":"function filters input data based specified date time column. input dataset must pub_date time columns, time period match given date. dataset wide format, first transformed long format using helper function vintages_long.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_releases_by_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Data Releases for a Specific Date — get_releases_by_date","text":"","code":"# Example data df <- dplyr::filter(reviser::gdp, id==\"US\")  # Get releases for a specific date date <- as.Date(\"2020-04-01\") releases_on_date <- get_releases_by_date(df, date)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_revision_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Revision Analysis Summary Statistics — get_revision_analysis","title":"Revision Analysis Summary Statistics — get_revision_analysis","text":"Calculates comprehensive set summary statistics hypothesis tests revisions initial final data releases.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_revision_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Revision Analysis Summary Statistics — get_revision_analysis","text":"","code":"get_revision_analysis(df, final_release, degree = 1, grouping_var = NULL)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_revision_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Revision Analysis Summary Statistics — get_revision_analysis","text":"df data frame containing initial data releases. Must include columns: time: time variable. value: observed values initial release. Optionally, release (release identifier) id (grouping variable). final_release data frame containing final release data. Must include columns: time: time variable (matching initial release data). value: observed values final release. degree integer 1 5 specifying level detail output: 1: Default, includes information revision size. 2: includes correlation statistics revision. 3: includes news noise tests. 4: includes sign switches, seasonality analysis Theil’s U. 5: Full set statistics tests. grouping_var character string specifying grouping variable data frame. Defaults pub_date release available.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_revision_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Revision Analysis Summary Statistics — get_revision_analysis","text":"data frame one row per grouping (applicable) columns summary statistics test results. resulting data frame class revision_summary.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_revision_analysis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Revision Analysis Summary Statistics — get_revision_analysis","text":"function performs variety statistical analyses understand nature revisions initial final data releases. function: Checks input data consistency transforms necessary. Merges initial final release datasets time variable optional grouping variables (id release). Computes summary statistics mean, standard deviation, range revisions. Performs hypothesis tests bias, efficiency, correlation using robust methods (e.g., Newey-West standard errors). Includes tests seasonality, noise, news effects. Key tests include: Bias Tests: Tests presence mean bias regression bias. Autocorrelation Seasonality: Tests serial correlation seasonal patterns revisions. Theil's U Statistics: Measures predictive accuracy initial releases relative final values. Noise vs. News: Differentiates unpredictable errors (noise) systematic adjustments (news). function supports grouped calculations based presence id release columns input. following statistics tests calculated: N: number observations group. Frequency: inferred data frequency (e.g., 12 monthly 4 quarterly data). Bias (mean): mean revision, testing whether revisions systematically biased. Bias (p-value): p-value t-test evaluating significance mean revision. Bias (robust p-value): Newey-West HAC robust p-value mean revision test. Minimum: minimum revision group. Maximum: maximum revision group. 10Q: 10th percentile revision. Median: median revision. 90Q: 90th percentile revision. MAR: mean absolute revision. Std. Dev.: standard deviation revisions, indicating variability. Noise/Signal: ratio standard deviation revisions standard deviation final values. Correlation: Pearson correlation revisions initial values, testing relationship. Correlation (p-value): p-value significance correlation. Autocorrelation (1st): first-order autocorrelation revisions, measuring persistence. Autocorrelation (1st p-value): p-value first-order autocorrelation test. Autocorrelation 1yr (Ljung-Box p-value): p-value Ljung-Box test higher-order autocorrelation. Theil's U1: normalized measure forecast accuracy, comparing root mean squared error (RMSE) revisions RMSE final initial values. Theil's U2: measure comparing forecast changes actual changes. Seasonality (Friedman p-value): p-value Friedman test seasonality revisions. News joint test (p-value): p-value joint news test. News test Intercept: estimated intercept news test regression. News test Intercept (std.err): standard error intercept news test regression. News test Intercept (p-value): p-value intercept news test regression. News test Coefficient: estimated coefficient value news test regression. News test Coefficient (std.err): standard error coefficient news test regression. News test Coefficient (p-value): p-value coefficient news test regression. Noise joint test (p-value): p-value joint noise test. Noise test Intercept: estimated intercept noise test regression. Noise test Intercept (std.err): standard error intercept noise test regression. Noise test Intercept (p-value): p-value intercept noise test regression. Noise test Coefficient: estimated coefficient final_value noise test regression. Noise test Coefficient (std.err): standard error coefficient noise test regression. Noise test Coefficient (p-value): p-value coefficient noise test regression. Fraction correct sign: fraction correct sign changes revisions. Fraction correct growth rate change: fraction correct sign changes growth rates revisions.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_revision_analysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Revision Analysis Summary Statistics — get_revision_analysis","text":"","code":"# Example usage: df <- get_nth_release(   dplyr::filter(     na.omit(       tsbox::ts_pc(         reviser::gdp)             ),         id==\"US\"      ),    n = 0:3  )  final_release <- get_nth_release(   dplyr::filter(   na.omit(   tsbox::ts_pc(     reviser::gdp)        ),     id==\"US\"    ),  n = \"latest\" )  results <- get_revision_analysis(   df,   final_release  ) #> Warning: Both 'release' and 'pub_date' columns are present in 'df. The 'release' column will be used.  print(results) #> # A tibble: 4 × 14 #>   id    release       N `Bias (mean)` `Bias (p-value)` `Bias (robust p-value)` #>   <chr> <chr>     <dbl>         <dbl>            <dbl>                   <dbl> #> 1 US    release_0   178        0.0229            0.300                  0.255  #> 2 US    release_1   177        0.0199            0.347                  0.288  #> 3 US    release_2   176        0.0218            0.311                  0.238  #> 4 US    release_3   175        0.0316            0.133                  0.0533 #> # ℹ 8 more variables: Minimum <dbl>, Maximum <dbl>, `10Q` <dbl>, Median <dbl>, #> #   `90Q` <dbl>, MAR <dbl>, `Std. Dev.` <dbl>, `Noise/Signal` <dbl>"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_revisions.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Revisions in Vintage Data — get_revisions","title":"Calculate Revisions in Vintage Data — get_revisions","text":"Computes revisions vintage data based specified reference points: fixed reference date, nth release, specified interval. function allows users analyze differences data vintages across time.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_revisions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Revisions in Vintage Data — get_revisions","text":"","code":"get_revisions(df, interval = NULL, nth_release = NULL, ref_date = NULL)"},{"path":"https://p-wegmueller.github.io/reviser/reference/get_revisions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Revisions in Vintage Data — get_revisions","text":"df data frame containing vintage data. data frame must include least following columns: pub_date: publication date vintage. time: reference period (e.g., quarter month). value: observed value given vintage reference period. interval positive integer specifying lag (periods) vintages compute revisions. Defaults 1 parameter specified. nth_release positive integer \"latest\", specifying release use reference revisions. \"latest\", recent vintage used. ref_date date specifying fixed reference publication date compare vintages .","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_revisions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Revisions in Vintage Data — get_revisions","text":"data frame (tibble) class tbl_revision, following columns: pub_date: publication date vintage. time: reference period (e.g., quarter month). value: calculated revision, .e., difference observed value reference value.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_revisions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Revisions in Vintage Data — get_revisions","text":"function supports three mutually exclusive methods calculating revisions: Reference date (ref_date): Computes revisions relative fixed publication date. Interval (interval): Computes revisions relative vintages published interval periods earlier. Nth release (nth_release): Computes revisions relative nth vintage release reference period. method explicitly specified, interval = 1 used default. Input validation ensures one ref_date, nth_release, interval specified.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/get_revisions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Revisions in Vintage Data — get_revisions","text":"","code":"# Example data df <- dplyr::filter(reviser::gdp , id==\"US\")  # Calculate revisions using an interval of 1 revisions_interval <- get_revisions(df, interval = 1)  # Calculate revisions using a fixed reference date revisions_date <- get_revisions(df, ref_date = as.Date(\"2023-02-01\"))  # Calculate revisions relative to the nth release (2nd release) revisions_nth <- get_revisions(df, nth_release = 1)"},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_matrices.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Matrices for the generalized Kishor-Koenig (KK) model — kk_matrices","title":"Create Matrices for the generalized Kishor-Koenig (KK) model — kk_matrices","text":"Constructs matrices \\(\\), \\(F\\), \\(G\\), \\(R\\), \\(H\\) used state-space models, specifically Kishor-Koenig (KK), Howrey, Classical frameworks.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_matrices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Matrices for the generalized Kishor-Koenig (KK) model — kk_matrices","text":"","code":"kk_matrices(e, model, params = NULL, type = \"numeric\")"},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_matrices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Matrices for the generalized Kishor-Koenig (KK) model — kk_matrices","text":"e Integer. number efficiency gaps (lags) model. Must greater 0. model Character. Specifies type model use. Options : \"Kishor-Koenig\" \"KK\" Uses Kishor-Koenig framework \\(e \\times (e+1)\\) parameters \\(G\\) matrix. \"Howrey\" Uses Howrey framework \\(e \\times e\\) parameters \\(G\\) matrix. \"Classical\" Uses diagonal identity matrix \\(G\\). params Numeric vector (optional). vector parameters initialize matrices. NULL, default values used: type = \"numeric\" vector params must supplied. type = \"character\" Initializes named parameters NA_real_. provided, length params must match number parameters required specified model. type Character. Specifies type matrices returned. Options : \"numeric\" Returns numeric matrices parameter values. \"character\" Returns character matrices parameter names. params provided, ignored.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_matrices.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Matrices for the generalized Kishor-Koenig (KK) model — kk_matrices","text":"list containing following components: II Identity matrix (\\(\\)). Size: \\((e+1) \\times (e+1)\\). FF State transition matrix (\\(F\\)). Size: \\((e+1) \\times (e+1)\\). GG Control matrix (\\(G\\)). Size depends model e. R State noise covariance matrix (\\(R\\)). Size: \\((e+1) \\times (e+1)\\). H Observation noise covariance matrix (\\(H\\)). Size: \\((e+1) \\times (e+1)\\). params vector parameters used construct matrices, including names.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_matrices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Matrices for the generalized Kishor-Koenig (KK) model — kk_matrices","text":"","code":"# Example 1: Kishor-Koenig model with character matrices matrices <- kk_matrices(e = 3, model = \"KK\", type = \"character\") str(matrices) #> List of 6 #>  $ II    : chr [1:4, 1:4] \"1\" \"0\" \"0\" \"0\" ... #>  $ FF    : chr [1:4, 1:4] \"0\" \"0\" \"0\" \"0\" ... #>  $ GG    : chr [1:4, 1:4] \"1\" \"G2_3\" \"G1_3\" \"G0_3\" ... #>  $ R     : chr [1:4, 1:4] \"0\" \"0\" \"0\" \"0\" ... #>  $ H     : chr [1:4, 1:4] \"0\" \"0\" \"0\" \"0\" ... #>  $ params: Named num [1:17] NA NA NA NA NA NA NA NA NA NA ... #>   ..- attr(*, \"names\")= chr [1:17] \"F0\" \"G0_0\" \"G0_1\" \"G0_2\" ...  # Example 2: Kishor-Koenig model with e = 2 params <- rep(0.1, 17) names(params) <- names(matrices$params) matrices <- kk_matrices(e = 3, params = params,  model = \"KK\", type = \"numeric\") str(matrices) #> List of 6 #>  $ II    : num [1:4, 1:4] 1 0 0 0 0 1 0 0 0 0 ... #>  $ FF    : num [1:4, 1:4] 0 0 0 0 1 0 0 0 0 1 ... #>  $ GG    : num [1:4, 1:4] 1 0.1 0.1 0.1 0 0.1 0.1 0.1 0 0.1 ... #>  $ R     : num [1:4, 1:4] 0 0 0 0 0 0 0 0 0 0 ... #>  $ H     : num [1:4, 1:4] 0 0 0 0 0 0.1 0 0 0 0 ... #>  $ params: Named num [1:17] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 ... #>   ..- attr(*, \"names\")= chr [1:17] \"F0\" \"G0_0\" \"G0_1\" \"G0_2\" ..."},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_nowcast.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Kishor-Koenig Model for Nowcasting — kk_nowcast","title":"Generalized Kishor-Koenig Model for Nowcasting — kk_nowcast","text":"Implements generalized Kishor-Koenig (KK) model nowcasting forecasting state-space models, allowing multiple vintages data, efficient estimation, Kalman filtering smoothing.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_nowcast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Kishor-Koenig Model for Nowcasting — kk_nowcast","text":"","code":"kk_nowcast(   df,   e,   h = 0,   model = \"Kishor-Koenig\",   method = \"SUR\",   solver_options = list() )"},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_nowcast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Kishor-Koenig Model for Nowcasting — kk_nowcast","text":"df data frame containing time series data either \"long\" \"wide\" format. must include columns time index different release vintages. e integer indicating number data vintages include model. Must greater 0. h integer specifying forecast horizon. Default 0, implies forecasts. Must greater equal 0. model string specifying type model use. Options : \"Kishor-Koenig\" \"KK\" (default): Full Kishor-Koenig model. \"Howrey\": Howrey's simplified framework. \"Classical\": Classical model without vintage effects. method string specifying estimation method use. Options \"SUR\" (default) \"OLS\". solver_options optional list control behaviour underlying systemfit::nlsystemfit() stats::nlm() solvers: trace: integer controlling level output optimization procedure. Default 0 (minimal output). maxiter: integer specifying maximum number iterations optimization procedure. Default 1000. startvals: list starting values optimization procedure (must match number parameters model). solvtol: Tolerance detecting linear dependencies columns X qr function calls (See systemfit::nlsystemfit()). Default .Machine$double.eps. gradtol: positive scalar giving tolerance scaled gradient considered close enough zero terminate algorithm (See stats::nlm()). Default 1e-6. steptol: positive scalar providing minimum allowable relative step length (See stats::nlm()). Default 1e-6.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_nowcast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Kishor-Koenig Model for Nowcasting — kk_nowcast","text":"list following components: filtered_z tibble filtered latent state variables based Kalman filter. filtered_y tibble filtered observed variables based Kalman filter. smoothed_z tibble smoothed latent state variables obtained using Kalman smoother. smoothed_y tibble smoothed observed variables obtained using Kalman smoother. forecast_z tibble forecasted latent state variables. Returned h > 0. forecast_y tibble forecasted observed variables. Returned h > 0. kk_model_mat list KK model matrices, transition observation matrices. ss_model_mat list state-space model matrices derived KK model. params Estimated model parameters, including covariance terms. fit fitted model object SUR estimation procedure. e number efficient release (0-indexed).","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_nowcast.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Kishor-Koenig Model for Nowcasting — kk_nowcast","text":"function supports multiple models, including full Kishor-Koenig framework, Howrey's model, classical approach. handles data preprocessing, estimation system equations using Seemingly Unrelated Regressions (SUR), application Kalman filter smoother. function requires well-structured input data multiple vintages. time series must regular, function automatically checks transforms data needed.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_nowcast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Kishor-Koenig Model for Nowcasting — kk_nowcast","text":"","code":"# Example usage: df <- get_nth_release(   tsbox::ts_span(     tsbox::ts_pc(       dplyr::filter(reviser::gdp, id==\"US\")       ),       start = \"1980-01-01\"      ),      n = 0:1    ) df <- na.omit(dplyr::select(df, -id))  e <- 1  # Number of efficient release h <- 2  # Forecast horizon model_result <- kk_nowcast(df, e, h = h, model = \"Kishor-Koenig\") #> Warning: Ignoring columns: pub_date #> Error in eval(predvars, data, env): object 'Ymat2' not found  model_result$params #> Error: object 'model_result' not found"},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_to_ss.html","id":null,"dir":"Reference","previous_headings":"","what":"Cast Generalized Kishor-Koenig Matrices into State-Space Form — kk_to_ss","title":"Cast Generalized Kishor-Koenig Matrices into State-Space Form — kk_to_ss","text":"Transforms generalized Kishor-Koenig (KK) matrices state-space representation required Kalman filtering smoothing.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_to_ss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cast Generalized Kishor-Koenig Matrices into State-Space Form — kk_to_ss","text":"","code":"kk_to_ss(II, FF, GG, R, H, epsilon = 1e-06)"},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_to_ss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cast Generalized Kishor-Koenig Matrices into State-Space Form — kk_to_ss","text":"II Matrix. identity matrix used observation state transition matrices. FF Matrix. state transition matrix defining state evolves time. GG Matrix. control matrix, representing influence state observations. R Matrix. state noise covariance matrix. H Matrix. observation noise covariance matrix. epsilon Numeric. small positive number ensure numerical stability covariance matrices (default: 1e-6).","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_to_ss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cast Generalized Kishor-Koenig Matrices into State-Space Form — kk_to_ss","text":"list containing state-space matrices: Z observation matrix. Tmat state transition matrix augmented state-space model. V observation noise covariance matrix. W state noise covariance matrix.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/kk_to_ss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cast Generalized Kishor-Koenig Matrices into State-Space Form — kk_to_ss","text":"","code":"# Define example matrices II <- diag(3) FF <- matrix(c(0.9, 0.1, 0, 0.1, 0.8, 0.1, 0, 0.1, 0.9), nrow = 3) GG <- matrix(c(0.8, 0.2, 0, 0.2, 0.7, 0.1, 0, 0.1, 0.8), nrow = 3) R <- diag(3) * 0.01 H <- diag(3) * 0.02  # Generate state-space matrices ss_matrices <- kk_to_ss(II, FF, GG, R, H) str(ss_matrices) #> List of 4 #>  $ Z   : num [1:3, 1:6] 1 0 0 0 1 0 0 0 1 1 ... #>  $ Tmat: num [1:6, 1:6] 0.9 0.1 0 0 0 0 0.1 0.8 0.1 0 ... #>  $ V   : num [1:3, 1:3] 0 0 0 0 0 0 0 0 0 #>  $ W   : num [1:6, 1:6] 1e-06 0e+00 0e+00 -2e-03 2e-03 0e+00 0e+00 1e-06 0e+00 2e-03 ..."},{"path":"https://p-wegmueller.github.io/reviser/reference/plot_vintages.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Vintages Data — plot_vintages","title":"Plot Vintages Data — plot_vintages","text":"flexible function visualize vintage data using various plot types line plots, point plots, bar plots, boxplots. function ensures input data validated appropriately transformed plotting.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/plot_vintages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Vintages Data — plot_vintages","text":"","code":"plot_vintages(   df,   type = \"line\",   dim_col = \"pub_date\",   time_col = \"time\",   title = \"\",   subtitle = \"\",   ylab = \"\" )"},{"path":"https://p-wegmueller.github.io/reviser/reference/plot_vintages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Vintages Data — plot_vintages","text":"df data frame containing vintage data plotted. Must include least two columns: one time (time) one value (value). type character string specifying type plot create. Options : \"line\": Line plot (default). \"point\": Scatter plot. \"bar\": Bar plot. \"boxplot\": Boxplot. dim_col character string specifying column name df represents publication dates grouping dimensions (e.g. \"release\"). Defaults \"pub_date\". time_col character string specifying column name df represents time variable. Defaults \"time\". title character string specifying title plot. Defaults empty string. subtitle character string specifying subtitle plot. Defaults empty string. ylab character string specifying label y-axis. Defaults empty string.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/plot_vintages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Vintages Data — plot_vintages","text":"ggplot2 plot object representing specified vintage data visualization.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/plot_vintages.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Vintages Data — plot_vintages","text":"plot_vintages function designed handle data frames wide long formats. ensures provided data frame includes necessary columns plotting. dim_col column contains 30 unique values, recent 30 plotted. Additionally, function supports custom themes color scales using scale_color_reviser, scale_fill_reviser, theme_reviser. function raises error : type argument one \"line\", \"point\", \"bar\", \"boxplot\". specified dim_col column df. title, subtitle, ylab character strings.","code":""},{"path":[]},{"path":"https://p-wegmueller.github.io/reviser/reference/plot_vintages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Vintages Data — plot_vintages","text":"","code":"# Example data df <- data.frame(   time = rep(seq.Date(from = as.Date(\"2022-01-01\"), by = \"month\", length.out = 12), 3),   value = runif(36, 50, 100),   pub_date = rep(c(\"2022-01-05\", \"2022-02-07\", \"2022-03-03\"), each = 12) )  # Line plot plot_vintages(   df,   type = \"line\",   dim_col = \"pub_date\",   title = \"Line plot\",   subtitle = \"Randomly generated data\"   )   # Point plot plot_vintages(   df,   type = \"point\",   dim_col = \"pub_date\",   title = \"Scatter plot\",   subtitle = \"Randomly generated data\"   )   # Bar plot plot_vintages(   df,   type = \"bar\",   dim_col = \"pub_date\",   title = \"Bar plot\",   subtitle = \"Randomly generated data\"   )   # Boxplot plot_vintages(   df,   type = \"boxplot\",   dim_col = \"pub_date\",   title = \"Boxplot\",   subtitle = \"Randomly generated data\"   )"},{"path":"https://p-wegmueller.github.io/reviser/reference/reviser-package.html","id":null,"dir":"Reference","previous_headings":"","what":"reviser: Tools for Studying Revision Properties in Real-Time Time Series Vintages — reviser-package","title":"reviser: Tools for Studying Revision Properties in Real-Time Time Series Vintages — reviser-package","text":"learn reviser, start vignettes: browseVignettes(package = \"reviser\")","code":""},{"path":[]},{"path":"https://p-wegmueller.github.io/reviser/reference/reviser-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"reviser: Tools for Studying Revision Properties in Real-Time Time Series Vintages — reviser-package","text":"Maintainer: Marc Burri marc.burri91@gmail.com (ORCID) [copyright holder] Authors: Philipp Wegmueller philipp.wemueller@seco.admin.ch [copyright holder]","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/summary.lst_efficient.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of Efficient Release Models — summary.lst_efficient","title":"Summary of Efficient Release Models — summary.lst_efficient","text":"Provides detailed summary regression model hypothesis test first efficient release identified get_first_efficient_release function.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/summary.lst_efficient.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of Efficient Release Models — summary.lst_efficient","text":"","code":"# S3 method for class 'lst_efficient' summary(object, ...)"},{"path":"https://p-wegmueller.github.io/reviser/reference/summary.lst_efficient.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of Efficient Release Models — summary.lst_efficient","text":"object output object get_first_efficient_release function. object must class list_eff_rel. ... Additional arguments (used).","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/summary.lst_efficient.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of Efficient Release Models — summary.lst_efficient","text":"Returns tibble following columns: id: identifier time series (present input data). e: index first efficient release. alpha: intercept coefficient regression model. beta: coefficient slope. p-value: p-value joint hypothesis test (alpha = 0 beta = 1). n_tested: number releases tested.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/summary.lst_efficient.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary of Efficient Release Models — summary.lst_efficient","text":"function prints following information: index first efficient release. summary regression model fitted efficient release, includes coefficients, R-squared values, relevant statistics. hypothesis test results efficient release, showing test statistic p-value null hypothesis unbiasedness efficiency. function assumes object includes: e: index first efficient release (0-based). models: list linear regression models release. tests: list hypothesis test results corresponding release.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/summary.lst_efficient.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of Efficient Release Models — summary.lst_efficient","text":"","code":"# Example usage df <- get_nth_release(tsbox::ts_pc(dplyr::filter(reviser::gdp , id==\"US\")), n = 1:4)  final_release <- get_nth_release(tsbox::ts_pc(dplyr::filter(reviser::gdp, id==\"US\")), n = 10)  # Identify the first efficient release result <- get_first_efficient_release(df, final_release, significance = 0.05) summary(result) #> Efficient release:  0  #>  #> Model summary:  #>  #> Call: #> stats::lm(formula = formula, data = df_wide) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -0.88971 -0.12583  0.02686  0.12286  0.69564  #>  #> Coefficients: #>              Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 0.0002137  0.0204027    0.01    0.992     #> release_1   0.9757504  0.0154917   62.98   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 0.231 on 166 degrees of freedom #>   (9 observations deleted due to missingness) #> Multiple R-squared:  0.9598,\tAdjusted R-squared:  0.9596  #> F-statistic:  3967 on 1 and 166 DF,  p-value: < 2.2e-16 #>  #>  #> Test summary:  #>  #> Linear hypothesis test: #> (Intercept) = 0 #> release_1 = 1 #>  #> Model 1: restricted model #> Model 2: final ~ release_1 #>  #> Note: Coefficient covariance matrix supplied. #>  #>   Res.Df Df      F Pr(>F) #> 1    168                  #> 2    166  2 2.2448 0.1092"},{"path":"https://p-wegmueller.github.io/reviser/reference/theme_reviser.html","id":null,"dir":"Reference","previous_headings":"","what":"Custom Visualization Theme and Color Scales for Reviser — theme_reviser","title":"Custom Visualization Theme and Color Scales for Reviser — theme_reviser","text":"functions provide custom visualization theme color scales use ggplot2, inspired tsbox package.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/theme_reviser.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Custom Visualization Theme and Color Scales for Reviser — theme_reviser","text":"","code":"theme_reviser(   base_size = 12,   legend.position = \"bottom\",   legend.direction = \"horizontal\" )  colors_reviser()  scale_color_reviser(...)  scale_fill_reviser(...)"},{"path":"https://p-wegmueller.github.io/reviser/reference/theme_reviser.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Custom Visualization Theme and Color Scales for Reviser — theme_reviser","text":"base_size Numeric. base font size theme. Default 12. legend.position Character. Position legend. Default \"bottom\". legend.direction Character. Direction legend. Default \"horizontal\". ... Additional arguments passed ggplot2 scale functions.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/theme_reviser.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Custom Visualization Theme and Color Scales for Reviser — theme_reviser","text":"customized ggplot2 theme, color palette, scale.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/theme_reviser.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Custom Visualization Theme and Color Scales for Reviser — theme_reviser","text":"theme_reviser: Defines minimal theme custom adjustments axis titles, plot titles, subtitles, captions, legend positioning. colors_reviser: Provides predefined set colors, including soft black, palette suitable colorblind readers, additional colors extended use. scale_color_reviser: ggplot2 color scale uses custom colors_reviser palette. scale_fill_reviser: ggplot2 fill scale uses custom colors_reviser palette.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/theme_reviser.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Custom Visualization Theme and Color Scales for Reviser — theme_reviser","text":"","code":"library(ggplot2) ggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +   geom_point(size = 3) +   theme_reviser() +   scale_color_reviser()"},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_long.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Vintages Data to Long Format — vintages_long","title":"Convert Vintages Data to Long Format — vintages_long","text":"Converts vintages dataset wide format long format, optionally adding id input list data frames. long format contains one row per combination time names_to (e.g., pub_date release), values stored single value column.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Vintages Data to Long Format — vintages_long","text":"","code":"vintages_long(df, names_to = \"pub_date\", keep_na = FALSE)"},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Vintages Data to Long Format — vintages_long","text":"df data frame, tibble, list data frames containing vintages data wide format. names_to name column create wide-format column names. Must either \"pub_date\" (default) \"release\". keep_na Logical. TRUE, retains rows NA values value column. Default FALSE.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_long.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Vintages Data to Long Format — vintages_long","text":"long-format data frame tibble. input list wide-format data frames, output single combined long-format data frame.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Vintages Data to Long Format — vintages_long","text":"","code":"# Example wide-format data long_data <- dplyr::filter(reviser::gdp, id==\"US\")  # Convert to wide format wide_data <- vintages_wide(long_data)  # Example list of wide-format data frames wide_list <- list(   A = wide_data$US,   B = wide_data$US )  # Convert list to long format long_data <- vintages_long(wide_list, names_to = \"pub_date\")"},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_rename.html","id":null,"dir":"Reference","previous_headings":"","what":"Rename Columns to Align with Package Standards — vintages_rename","title":"Rename Columns to Align with Package Standards — vintages_rename","text":"Renames columns data frame tibble align conventions used package. Converts renamed columns appropriate data types.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_rename.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rename Columns to Align with Package Standards — vintages_rename","text":"","code":"vintages_rename(   df,   col_time = NULL,   col_pub_date = NULL,   col_value = NULL,   col_release = NULL,   col_id = NULL )"},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_rename.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rename Columns to Align with Package Standards — vintages_rename","text":"df data frame tibble containing data renamed. col_time Optional. name column renamed time. time column represents observation dates converted Date format. col_pub_date Optional. name column renamed pub_date. pub_date column represents release dates converted Date format. col_value Optional. name column renamed value. value column represents observed values converted numeric. col_release Optional. name column renamed release. id column used identifier converted character format. col_id Optional. name column renamed id.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_rename.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rename Columns to Align with Package Standards — vintages_rename","text":"data frame tibble renamed columns respective data types converted (specified). original class input object preserved.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_rename.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rename Columns to Align with Package Standards — vintages_rename","text":"function checks validity input data frame ensures least one column specified renaming. column renamed, also converted expected data type: time pub_date converted Date. value converted numeric. release id converted character.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_rename.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rename Columns to Align with Package Standards — vintages_rename","text":"","code":"# Example data data <- tibble::tibble(   observation_date = seq.Date(as.Date(\"2020-01-01\"), as.Date(\"2020-06-01\"), by = \"month\"),   release_date = seq.Date(as.Date(\"2020-01-15\"), as.Date(\"2020-06-15\"), by = \"month\"),   observed_value = rnorm(6),   identifier = rep(\"A\", 6) )  # Rename columns renamed_data <- vintages_rename(   data,   col_time = observation_date,   col_pub_date = release_date,   col_value = observed_value,   col_id = identifier )"},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_wide.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Vintages Data to Wide Format — vintages_wide","title":"Convert Vintages Data to Wide Format — vintages_wide","text":"Converts vintages dataset long format wide format, optionally grouping id present. wide format uses one column per unique value names_from parameter, observation dates (time) rows values (value) cell contents.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_wide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Vintages Data to Wide Format — vintages_wide","text":"","code":"vintages_wide(df, names_from = \"pub_date\")"},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_wide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Vintages Data to Wide Format — vintages_wide","text":"df data frame tibble containing vintages data long format. names_from name column whose unique values used column names wide format. Defaults \"pub_date\". : \"release\".","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_wide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Vintages Data to Wide Format — vintages_wide","text":"id column present, function returns named list wide-format data frames, one unique id. Otherwise, returns single wide-format data frame.","code":""},{"path":"https://p-wegmueller.github.io/reviser/reference/vintages_wide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Vintages Data to Wide Format — vintages_wide","text":"","code":"# Example wide-format data long_data <- dplyr::filter(reviser::gdp, id==\"US\")  # Convert to wide format wide_data <- vintages_wide(long_data)  # Example list of wide-format data frames wide_list <- list(   A = wide_data$US,   B = wide_data$US )  # Convert list to long format long_data1 <- vintages_long(wide_data, names_to = \"pub_date\") long_data2 <- vintages_long(wide_list, names_to = \"pub_date\")"}]
